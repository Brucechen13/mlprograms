{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据预处理\n",
    "按照中文词组、中文单字、中文拼音方式分词\n",
    "\n",
    "根据预训练好的word2vec和fasttext词典构建词向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chenchi/anaconda3/envs/py27/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.205 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "stdi, stdo, stde = sys.stdin, sys.stdout, sys.stderr\n",
    "reload(sys)\n",
    "sys.setdefaultencoding('utf-8')\n",
    "sys.stdin, sys.stdout, sys.stderr = stdi, stdo, stde\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tflearn.data_utils import pad_sequences\n",
    "from collections import Counter \n",
    "from langconv import *\n",
    "import os\n",
    "import csv\n",
    "import jieba\n",
    "jieba.add_word('花呗')\n",
    "jieba.add_word('借呗')\n",
    "jieba.add_word('收钱码')\n",
    "jieba.add_word('收款码')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('../data/aux/train_parse.csv', sep='\\t', header=None)#train\n",
    "test_data = pd.read_csv('../data/test/test.csv', sep='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>﻿怎么更改花呗手机号码</td>\n",
       "      <td>我的花呗是以前的手机号码，怎么更改成现在的支付宝的号码手机号</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>也开不了花呗，就这样了？完事了</td>\n",
       "      <td>真的嘛？就是花呗付款</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>花呗冻结以后还能开通吗</td>\n",
       "      <td>我的条件可以开通花呗借款吗</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>如何得知关闭借呗</td>\n",
       "      <td>想永久关闭借呗</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>花呗扫码付钱</td>\n",
       "      <td>二维码扫描可以用花呗吗</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0                1                               2  3\n",
       "0  1      ﻿怎么更改花呗手机号码  我的花呗是以前的手机号码，怎么更改成现在的支付宝的号码手机号  1\n",
       "1  2  也开不了花呗，就这样了？完事了                      真的嘛？就是花呗付款  0\n",
       "2  3      花呗冻结以后还能开通吗                   我的条件可以开通花呗借款吗  0\n",
       "3  4         如何得知关闭借呗                         想永久关闭借呗  0\n",
       "4  5           花呗扫码付钱                     二维码扫描可以用花呗吗  0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 98976 entries, 0 to 98975\n",
      "Data columns (total 4 columns):\n",
      "0    98976 non-null int64\n",
      "1    98976 non-null object\n",
      "2    98976 non-null object\n",
      "3    98976 non-null int64\n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 3.0+ MB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(98976, 4)\n"
     ]
    }
   ],
   "source": [
    "# 转换繁体到简体\n",
    "def cht_to_chs(line):\n",
    "    line = Converter('zh-hans').convert(line)\n",
    "    line.encode('utf-8')\n",
    "    return line\n",
    "def parse_df(df):\n",
    "    size = df.shape[0]\n",
    "    parse_data = df.copy()\n",
    "    for i in range(size):\n",
    "        parse_data.iloc[i, 1] = cht_to_chs(df.iloc[i, 1].decode('UTF-8'))\n",
    "        parse_data.iloc[i, 2] = cht_to_chs(df.iloc[i, 2].decode('UTF-8'))\n",
    "    return parse_data\n",
    "train_data = parse_df(train_data)\n",
    "test_data = parse_df(test_data)\n",
    "train_data.to_csv('../data/aux/train_parse.csv', sep='\\t', header=None, index=False)\n",
    "print train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PAD_ID = 0\n",
    "UNK_ID=1\n",
    "def translate(text, translation):\n",
    "    for token, replacement in translation.items():\n",
    "        text = text.replace(token, ' ' + replacement + ' ')\n",
    "    text = text.replace('  ', ' ')\n",
    "    return text\n",
    "def token_string_as_list(string, token_string='char'):\n",
    "    string = string.decode('UTF-8')\n",
    "    translation = {\n",
    "        '***':'*',\n",
    "        '花被':'花呗'\n",
    "    }\n",
    "    translate(string, translation)\n",
    "    length = len(string)\n",
    "    if token_string == 'char':\n",
    "        listt = [string[i] for i in range(length)]\n",
    "    elif token_string == 'word':\n",
    "        listt = jieba.lcut(string)\n",
    "    elif token_string == 'pinyin':\n",
    "        string = ''.join(jibe.lcut(string))\n",
    "        listt = ''.join(lazy_pinyin(string)).split()\n",
    "    listt = [item for item in listt if item.strip()]\n",
    "    return listt\n",
    "def create_voca(train_data, token_string='char', voca_size=5000):\n",
    "    size = train_data.shape[0]\n",
    "    input_count = Counter()\n",
    "    for i in range(size):\n",
    "        #print train_data.iloc[i, 0], train_data.iloc[i, 1]\n",
    "        token_list = token_string_as_list(train_data.iloc[i, 1], token_string=token_string)\n",
    "        input_count.update(token_list)\n",
    "        token_list = token_string_as_list(train_data.iloc[i, 2], token_string=token_string)\n",
    "        input_count.update(token_list)\n",
    "    vocab_worddict = {}\n",
    "    vocab_indexdict = {}\n",
    "    vocab_list = input_count.most_common(voca_size)\n",
    "    for i, tuplee in enumerate(vocab_list):\n",
    "        word,_ = tuplee\n",
    "        vocab_worddict[i+2] = word\n",
    "        vocab_indexdict[word] = i+2\n",
    "    return vocab_worddict, vocab_indexdict\n",
    "def parse_train_data(train_data, vocab_indexdict, token_string):\n",
    "    size = train_data.shape[0]\n",
    "    input_count = Counter()\n",
    "    parse_data = train_data.copy()\n",
    "    temp_data = train_data.copy()\n",
    "    for i in range(size):\n",
    "        token_list1 = token_string_as_list(train_data.iloc[i, 1], token_string=token_string)\n",
    "        token_list2 = token_string_as_list(train_data.iloc[i, 2], token_string=token_string)\n",
    "        temp_data.iloc[i, 1] = ' '.join(token_list1)\n",
    "        temp_data.iloc[i, 2] = ' '.join(token_list2)\n",
    "        parse_data.iloc[i, 1] = ' '.join([str(vocab_indexdict[item]) for item in token_list1 if item in vocab_indexdict])\n",
    "        parse_data.iloc[i, 2] = ' '.join([str(vocab_indexdict[item]) for item in token_list2 if item in vocab_indexdict])\n",
    "    if token_string == 'word':\n",
    "        temp_data.to_csv('../data/aux/train_word.csv', sep='\\t', header=None, index=False)\n",
    "    return parse_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#vocab_worddict_char, vocab_indexdict_char = create_voca(train_data, token_string='char')\n",
    "vocab_worddict_word, vocab_indexdict_word = create_voca(train_data, token_string='word')\n",
    "parse_data2 = parse_train_data(train_data, vocab_indexdict_word,token_string='word')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "# jsObj = json.dumps(vocab_indexdict_char)  \n",
    "# fileObject = open('../data/aux/vocab_indexdict_char.json', 'w')  \n",
    "# fileObject.write(jsObj)  \n",
    "# fileObject.close()  \n",
    "jsObj = json.dumps(vocab_indexdict_word)  \n",
    "fileObject = open('../data/aux/vocab_indexdict_word.json', 'w')  \n",
    "fileObject.write(jsObj)  \n",
    "fileObject.close()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#parse_data1 = parse_train_data(train_data, vocab_indexdict_char,token_string='char')\n",
    "parse_data2 = parse_train_data(train_data, vocab_indexdict_word,token_string='word')\n",
    "#parse_data1.to_csv('../data/aux/train_char_indexvec.csv', index=False)\n",
    "parse_data2.to_csv('../data/aux/train_word_indexvec.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "构建词向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "def load_word_vec(file_path):\n",
    "    source_object = open(file_path, 'r')\n",
    "    word_vec_dict={}\n",
    "    for i,line in enumerate(source_object):\n",
    "        if i==0 and 'word2vec' in file_path:\n",
    "            continue\n",
    "        line=line.strip()\n",
    "        line_list=line.split()\n",
    "        word=line_list[0].decode(\"utf-8\")\n",
    "        vec_list=[float(x) for x in line_list[1:]]\n",
    "        word_vec_dict[word]=np.array(vec_list)\n",
    "    #print(\"word_vec_dict:\",word_vec_dict)\n",
    "    return word_vec_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/aux/vocab_indexdict_char.json') as f:\n",
    "    vocab_worddict_char = json.load(f)\n",
    "with open('../data/aux/vocab_indexdict_word.json') as f:\n",
    "    vocab_worddict_word = json.load(f)\n",
    "\n",
    "\n",
    "word_vec_fasttext_dict=load_word_vec('../data/aux/fasttext.vec') #word embedding from fasttxt\n",
    "word_vec_word2vec_dict = load_word_vec('../data/aux/word2vec.txt') #word embedding from word2vec\n",
    "word_char_dict = load_word_vec('../data/word-character')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2085\n",
      "5000\n"
     ]
    }
   ],
   "source": [
    "print len(vocab_worddict_char)\n",
    "print len(vocab_worddict_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "636037"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_char_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((len(vocab_worddict_word) + 2, 300))\n",
    "for word, index in vocab_worddict_word.items():\n",
    "    embedding_vector = word_vec_fasttext_dict.get(word)\n",
    "    #import pdb;pdb.set_trace()\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[index][:50] = embedding_vector\n",
    "    elif word in word_char_dict:\n",
    "        embedding_matrix[index] = word_char_dict.get(word)\n",
    "\n",
    "np.save(\"../data/aux/vec_word.npy\",embedding_matrix)\n",
    "\n",
    "embedding_matrix = np.zeros((len(vocab_worddict_char) + 2, 300))\n",
    "for word, index in vocab_worddict_char.items():\n",
    "    if word in word_char_dict:\n",
    "        embedding_matrix[index] = word_char_dict.get(word)\n",
    "\n",
    "np.save(\"../data/aux/vec_char.npy\",embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.094878, -0.274933,  0.274207, -0.173418,  0.224209, -0.044867,\n",
       "        0.250689, -0.012698, -0.075608,  0.079465,  0.194921,  0.12656 ,\n",
       "       -0.118317,  0.356042,  0.191383,  0.077959, -0.334946,  0.212342,\n",
       "        0.07326 ,  0.254857, -0.077326, -0.016247,  0.249023,  0.253988,\n",
       "        0.145813,  0.310039, -0.22933 , -0.195232, -0.207432,  0.04946 ,\n",
       "        0.444571,  0.053893, -0.276234,  0.119278,  0.123157, -0.154975,\n",
       "        0.159252, -0.233318,  0.041756,  0.096739,  0.125562, -0.132592,\n",
       "        0.085903,  0.127125,  0.079671, -0.026953, -0.028784, -0.138333,\n",
       "       -0.06711 ,  0.119755,  0.046799, -0.043481,  0.240149,  0.068734,\n",
       "        0.105269, -0.009649, -0.056001, -0.058492,  0.184133,  0.175659,\n",
       "        0.105764, -0.158145,  0.140379,  0.111549,  0.043281,  0.251387,\n",
       "       -0.36871 ,  0.198847, -0.27882 , -0.132679,  0.119707,  0.019584,\n",
       "        0.00324 ,  0.012386, -0.111798,  0.121082, -0.044826, -0.02054 ,\n",
       "        0.0914  ,  0.009025,  0.028984, -0.182722,  0.29201 ,  0.113844,\n",
       "        0.034013,  0.100905,  0.012306, -0.067867,  0.006184, -0.12642 ,\n",
       "       -0.002011, -0.137232,  0.104949,  0.277785,  0.137446, -0.184613,\n",
       "        0.012122, -0.284453, -0.150924, -0.013909, -0.303557,  0.317584,\n",
       "        0.147299,  0.019793,  0.284551,  0.203379, -0.063318,  0.396895,\n",
       "        0.165449, -0.154071,  0.071075, -0.019334,  0.261486, -0.06857 ,\n",
       "       -0.046355,  0.145587, -0.180669, -0.024765,  0.32199 , -0.247401,\n",
       "       -0.035146,  0.080809, -0.145087,  0.037437, -0.354678,  0.017842,\n",
       "       -0.088077,  0.102718, -0.205191,  0.260816, -0.044555,  0.110716,\n",
       "        0.287307,  0.096223, -0.071212,  0.1464  , -0.060252,  0.218102,\n",
       "        0.208891,  0.072686, -0.216094,  0.154173,  0.098831, -0.153895,\n",
       "        0.307251,  0.260012, -0.051233, -0.040298,  0.047562,  0.154313,\n",
       "        0.229691, -0.21039 , -0.029301, -0.076987, -0.012114, -0.313964,\n",
       "       -0.0426  , -0.06395 , -0.063147,  0.240689, -0.127372, -0.084933,\n",
       "        0.082212,  0.057032, -0.039863,  0.075902,  0.007053, -0.005749,\n",
       "        0.061875,  0.077704, -0.121254,  0.002863, -0.094465, -0.155537,\n",
       "        0.127947,  0.179621,  0.090322, -0.309161, -0.004828, -0.114817,\n",
       "        0.001999, -0.188474,  0.187122,  0.312603, -0.139593, -0.010192,\n",
       "       -0.333646,  0.293221, -0.074057, -0.187107,  0.251533, -0.273394,\n",
       "       -0.263444,  0.017013,  0.15002 ,  0.140665,  0.08419 ,  0.119396,\n",
       "        0.129275,  0.618051, -0.212011, -0.071488,  0.215845,  0.04462 ,\n",
       "        0.070787,  0.25244 , -0.258095,  0.187398, -0.051598,  0.095321,\n",
       "        0.078074,  0.169679, -0.14562 ,  0.030661,  0.207491,  0.203143,\n",
       "       -0.090217,  0.036359,  0.095644, -0.031053, -0.083376,  0.091364,\n",
       "        0.320999, -0.247943, -0.04621 , -0.016102, -0.321505,  0.060189,\n",
       "       -0.14727 , -0.014809,  0.058941,  0.156086, -0.163194,  0.222022,\n",
       "        0.251483,  0.030609, -0.189757, -0.127424,  0.007636, -0.298774,\n",
       "       -0.012425, -0.026887, -0.331316,  0.037935, -0.219021,  0.08569 ,\n",
       "        0.027602, -0.065382, -0.168667, -0.092248, -0.099468,  0.056972,\n",
       "        0.211916, -0.002636,  0.027573, -0.196366, -0.086289,  0.354706,\n",
       "       -0.084733, -0.000742,  0.024231,  0.053453,  0.218261,  0.290291,\n",
       "        0.034256,  0.022   , -0.015943,  0.172148,  0.174758,  0.042891,\n",
       "       -0.0917  ,  0.21749 , -0.072204,  0.036377, -0.040756, -0.210419,\n",
       "        0.082549,  0.021682,  0.060982,  0.027674,  0.062678, -0.317832,\n",
       "        0.093509,  0.093837,  0.135514, -0.236712,  0.308285,  0.034023,\n",
       "       -0.154636,  0.219962,  0.07556 ,  0.341729,  0.01552 , -0.114372,\n",
       "        0.087371,  0.273176,  0.407387,  0.302083, -0.19166 ,  0.047485])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50,)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vec_fasttext_dict[u'花呗'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "﻿\n",
      "玏\n",
      "睌\n",
      "叧\n",
      "徣\n",
      "嚒\n",
      "呮\n",
      "挷\n",
      "幵\n",
      "牫\n",
      "鈤\n",
      "肔\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for key in vocab_worddict_char:\n",
    "    #\n",
    "    if key not in word_char_dict:\n",
    "        #if key in word_vec_fasttext_dict:\n",
    "        print key\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1267"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab_worddict_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(vocab_worddict_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u'借呗' in word_vec_fasttext_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50,)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vec_fasttext_dict[u'借呗'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_char_dict[u'银行'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.zeros((300, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[:50] = word_vec_fasttext_dict[u'借呗']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.27397 ,  0.64121 , -0.22201 ,  0.31229 ,  0.62923 ,  0.17857 ,\n",
       "        0.23869 ,  0.96237 ,  0.23135 ,  0.13782 , -0.034528,  0.18526 ,\n",
       "       -0.33951 , -0.91978 , -0.16099 , -0.34089 , -0.58058 ,  0.52549 ,\n",
       "        0.81099 ,  0.37196 , -0.094091, -0.24108 , -0.43252 , -0.61711 ,\n",
       "       -0.1377  ,  0.039142,  0.10998 , -1.0043  , -0.22509 ,  1.5202  ,\n",
       "       -0.17654 ,  0.63722 ,  0.31804 ,  0.29838 ,  0.038973, -0.36773 ,\n",
       "       -0.070742,  0.060467, -0.24382 , -0.42763 , -0.072725,  0.066941,\n",
       "       -0.12018 ,  0.51183 ,  1.8377  ,  0.3385  , -0.08096 , -0.24191 ,\n",
       "       -0.10926 ,  0.038589,  0.      ,  0.      ,  0.      ,  0.      ,\n",
       "        0.      ,  0.      ,  0.      ,  0.      ,  0.      ,  0.      ,\n",
       "        0.      ,  0.      ,  0.      ,  0.      ,  0.      ,  0.      ,\n",
       "        0.      ,  0.      ,  0.      ,  0.      ,  0.      ,  0.      ,\n",
       "        0.      ,  0.      ,  0.      ,  0.      ,  0.      ,  0.      ,\n",
       "        0.      ,  0.      ,  0.      ,  0.      ,  0.      ,  0.      ,\n",
       "        0.      ,  0.      ,  0.      ,  0.      ,  0.      ,  0.      ,\n",
       "        0.      ,  0.      ,  0.      ,  0.      ,  0.      ,  0.      ,\n",
       "        0.      ,  0.      ,  0.      ,  0.      ,  0.      ,  0.      ,\n",
       "        0.      ,  0.      ,  0.      ,  0.      ,  0.      ,  0.      ,\n",
       "        0.      ,  0.      ,  0.      ,  0.      ,  0.      ,  0.      ,\n",
       "        0.      ,  0.      ,  0.      ,  0.      ,  0.      ,  0.      ,\n",
       "        0.      ,  0.      ,  0.      ,  0.      ,  0.      ,  0.      ,\n",
       "        0.      ,  0.      ,  0.      ,  0.      ,  0.      ,  0.      ,\n",
       "        0.      ,  0.      ,  0.      ,  0.      ,  0.      ,  0.      ,\n",
       "        0.      ,  0.      ,  0.      ,  0.      ,  0.      ,  0.      ,\n",
       "        0.      ,  0.      ,  0.      ,  0.      ,  0.      ,  0.      ,\n",
       "        0.      ,  0.      ,  0.      ,  0.      ,  0.      ,  0.      ,\n",
       "        0.      ,  0.      ,  0.      ,  0.      ,  0.      ,  0.      ,\n",
       "        0.      ,  0.      ,  0.      ,  0.      ,  0.      ,  0.      ,\n",
       "        0.      ,  0.      ,  0.      ,  0.      ,  0.      ,  0.      ,\n",
       "        0.      ,  0.      ,  0.      ,  0.      ,  0.      ,  0.      ,\n",
       "        0.      ,  0.      ,  0.      ,  0.      ,  0.      ,  0.      ,\n",
       "        0.      ,  0.      ,  0.      ,  0.      ,  0.      ,  0.      ,\n",
       "        0.      ,  0.      ,  0.      ,  0.      ,  0.      ,  0.      ,\n",
       "        0.      ,  0.      ,  0.      ,  0.      ,  0.      ,  0.      ,\n",
       "        0.      ,  0.      ,  0.      ,  0.      ,  0.      ,  0.      ,\n",
       "        0.      ,  0.      ,  0.      ,  0.      ,  0.      ,  0.      ,\n",
       "        0.      ,  0.      ,  0.      ,  0.      ,  0.      ,  0.      ,\n",
       "        0.      ,  0.      ,  0.      ,  0.      ,  0.      ,  0.      ,\n",
       "        0.      ,  0.      ,  0.      ,  0.      ,  0.      ,  0.      ,\n",
       "        0.      ,  0.      ,  0.      ,  0.      ,  0.      ,  0.      ,\n",
       "        0.      ,  0.      ,  0.      ,  0.      ,  0.      ,  0.      ,\n",
       "        0.      ,  0.      ,  0.      ,  0.      ,  0.      ,  0.      ,\n",
       "        0.      ,  0.      ,  0.      ,  0.      ,  0.      ,  0.      ,\n",
       "        0.      ,  0.      ,  0.      ,  0.      ,  0.      ,  0.      ,\n",
       "        0.      ,  0.      ,  0.      ,  0.      ,  0.      ,  0.      ,\n",
       "        0.      ,  0.      ,  0.      ,  0.      ,  0.      ,  0.      ,\n",
       "        0.      ,  0.      ,  0.      ,  0.      ,  0.      ,  0.      ,\n",
       "        0.      ,  0.      ,  0.      ,  0.      ,  0.      ,  0.      ,\n",
       "        0.      ,  0.      ,  0.      ,  0.      ,  0.      ,  0.      ,\n",
       "        0.      ,  0.      ,  0.      ,  0.      ,  0.      ,  0.      ])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
