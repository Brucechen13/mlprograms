{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BILSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tflearn.data_utils import pad_sequences\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from keras.layers import *\n",
    "from keras.models import Sequential\n",
    "import tensorflow as tf\n",
    "import keras.backend.tensorflow_backend as KTF\n",
    "from keras import initializers\n",
    "import os\n",
    "import keras\n",
    "import jieba\n",
    "from collections import Counter \n",
    "jieba.add_word('花呗')\n",
    "jieba.add_word('借呗')\n",
    "jieba.add_word('收钱码')\n",
    "jieba.add_word('收款码')\n",
    "\n",
    "from keras.optimizers import Adadelta\n",
    "import gc\n",
    "\n",
    "config = tf.ConfigProto()  \n",
    "config.gpu_options.allow_growth=True   #不全部占满显存, 按需分配\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "KTF.set_session(sess)\n",
    "\n",
    "EMBEDDING_DIM = 300\n",
    "VOCAB_LENGTH = 3000\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "\n",
    "\n",
    "embedding_matrix_char = np.load('../data/aux/vec_char.npy')\n",
    "\n",
    "embedding_matrix_word = np.load('../data/aux/vec_word.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0                                                  1                                                  2  3\n",
      "0   1002       65 91 10 26 27 6 2 52 15 4 97 21 23 38 31 35                           65 91 52 70 79 31 35 6 2  1\n",
      "1  39267                 3 2 83 48 242 58 35 229 15 4 65 91                      15 4 105 83 242 58 35 229 3 2  1\n",
      "2   3732              12 263 443 134 6 2 184 162 310 259 10                   6 2 184 162 310 259 20 513 175 9  0\n",
      "3  17937  24 17 4 40 59 38 7 9 3 2 5 12 18 383 340 51 11...  7 9 3 2 116 103 9 56 75 54 73 98 12 11 10 7 59...  0\n",
      "4   6929                               26 27 6 2 6 12 10 33                         15 4 7 9 26 27 6 2 6 12 10  1\n"
     ]
    }
   ],
   "source": [
    "train_data_char = pd.read_csv('../dfc_split.csv', header=None)\n",
    "train_data_word = pd.read_csv('../dfw_split.csv', header=None)\n",
    "print train_data_char.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'\\u82b1\\u5457', u'\\u5206\\u671f', u'\\u67e5\\u8be2']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jieba.lcut('花呗分期查询'.decode('UTF-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### 分词、分字\n",
    "PAD_ID = 0\n",
    "UNK_ID=1\n",
    "\n",
    "def translate(text, translation):\n",
    "    for token, replacement in translation.items():\n",
    "        text = text.replace(token, ' ' + replacement + ' ')\n",
    "    text = text.replace('  ', ' ')\n",
    "    return text\n",
    "def token_string_as_list(string, token_string='char'):\n",
    "    string = string.decode('UTF-8')\n",
    "    translation = {\n",
    "        '***':'*',\n",
    "        u'花被':u'花呗'\n",
    "    }\n",
    "    translate(string, translation)\n",
    "    length = len(string)\n",
    "    if token_string == 'char':\n",
    "        listt = [string[i] for i in range(length)]\n",
    "    elif token_string == 'word':\n",
    "        listt = jieba.lcut(string)\n",
    "    elif token_string == 'pinyin':\n",
    "        string = ''.join(jibe.lcut(string))\n",
    "        listt = ''.join(lazy_pinyin(string)).split()\n",
    "    listt = [item for item in listt if item.strip()]\n",
    "    return listt\n",
    "def create_voca(train_data, token_string='char', voca_size=5000):\n",
    "    size = train_data.shape[0]\n",
    "    input_count = Counter()\n",
    "    for i in range(size):\n",
    "        token_list = token_string_as_list(train_data.iloc[i, 1], token_string=token_string)\n",
    "        input_count.update(token_list)\n",
    "        token_list = token_string_as_list(train_data.iloc[i, 2], token_string=token_string)\n",
    "        input_count.update(token_list)\n",
    "    vocab_worddict = {}\n",
    "    vocab_indexdict = {}\n",
    "    vocab_list = input_count.most_common(voca_size)\n",
    "    for i, tuplee in enumerate(vocab_list):\n",
    "        word,_ = tuplee\n",
    "        vocab_worddict[i+2] = word\n",
    "        vocab_indexdict[word] = i+2\n",
    "    return vocab_worddict, vocab_indexdict\n",
    "def parse_train_data(train_data, vocab_indexdict, token_string):\n",
    "    size = train_data.shape[0]\n",
    "    input_count = Counter()\n",
    "    parse_data = train_data.copy()\n",
    "    temp_data = train_data.copy()\n",
    "    for i in range(size):\n",
    "        token_list1 = token_string_as_list(train_data.iloc[i, 1], token_string=token_string)\n",
    "        token_list2 = token_string_as_list(train_data.iloc[i, 2], token_string=token_string)\n",
    "        temp_data.iloc[i, 1] = ' '.join(token_list1)\n",
    "        temp_data.iloc[i, 2] = ' '.join(token_list2)\n",
    "        parse_data.iloc[i, 1] = ' '.join([str(vocab_indexdict[item]) for item in token_list1 if item in vocab_indexdict])\n",
    "        parse_data.iloc[i, 2] = ' '.join([str(vocab_indexdict[item]) for item in token_list2 if item in vocab_indexdict])\n",
    "    return parse_data\n",
    "\n",
    "def parse_split(train_data):\n",
    "    vocab_worddict_word, vocab_indexdict_word = create_voca(train_data, token_string='char')\n",
    "    parse_data = parse_train_data(train_data, vocab_indexdict_word,token_string='char')\n",
    "    return parse_data\n",
    "\n",
    "train_data_char_df = parse_split(train_data_char)\n",
    "\n",
    "def parse_split2(train_data):\n",
    "    vocab_worddict_word, vocab_indexdict_word = create_voca(train_data, token_string='word')\n",
    "    parse_data = parse_train_data(train_data, vocab_indexdict_word,token_string='word')\n",
    "    return parse_data\n",
    "train_data_word_df = parse_split2(train_data_char)\n",
    "\n",
    "train_data_char_df.to_csv('../dfc_split.csv', index=False, header=False)\n",
    "train_data_word_df.to_csv('../dfw_split.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1002</td>\n",
       "      <td>48 7 13 3 45 10 136 14 29 19</td>\n",
       "      <td>48 45 49 19 3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39267</td>\n",
       "      <td>2 109 217 417 10 48</td>\n",
       "      <td>10 77 217 417 2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3732</td>\n",
       "      <td>25 490 75 3 352 247 7</td>\n",
       "      <td>3 352 247 18 693 5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17937</td>\n",
       "      <td>15 32 39 4 5 2 11 21 430 28 115 26 43 14 88</td>\n",
       "      <td>4 5 2 76 5 1504 56 119 7 4 39 52 106 162 67 31...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6929</td>\n",
       "      <td>13 3 54 31 23</td>\n",
       "      <td>10 4 5 13 3 54 31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0                                            1                                                  2  3\n",
       "0   1002                 48 7 13 3 45 10 136 14 29 19                                      48 45 49 19 3  1\n",
       "1  39267                          2 109 217 417 10 48                                    10 77 217 417 2  1\n",
       "2   3732                        25 490 75 3 352 247 7                                 3 352 247 18 693 5  0\n",
       "3  17937  15 32 39 4 5 2 11 21 430 28 115 26 43 14 88  4 5 2 76 5 1504 56 119 7 4 39 52 106 162 67 31...  0\n",
       "4   6929                                13 3 54 31 23                                  10 4 5 13 3 54 31  1"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_word_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "VOC_SIZE_CHAR = 2087\n",
    "VOC_SIZE_WORD = 5002\n",
    "from keras.layers import *\n",
    "from keras.activations import softmax\n",
    "from keras.models import Model\n",
    "\n",
    "def unchanged_shape(input_shape):\n",
    "    return input_shape\n",
    "\n",
    "def time_distributed(x, layers):\n",
    "    for l in layers:\n",
    "        x = TimeDistributed(l)(x)\n",
    "    return x\n",
    "\n",
    "def align(input_1, input_2):\n",
    "    attention = Dot(axes=-1)([input_1, input_2])\n",
    "    w_att_1 = Lambda(lambda x: softmax(x, axis=1),\n",
    "                     output_shape=unchanged_shape)(attention)\n",
    "    w_att_2 = Permute((2,1))(Lambda(lambda x: softmax(x, axis=2),\n",
    "                             output_shape=unchanged_shape)(attention))\n",
    "    in1_aligned = Dot(axes=1)([w_att_1, input_1])\n",
    "    in2_aligned = Dot(axes=1)([w_att_2, input_2])\n",
    "    return in1_aligned, in2_aligned\n",
    "\n",
    "def aggregate_both(x1, x2, num_class, dense_dim=100, dropout_rate=0.2, activation=\"relu\"):#\n",
    "    feat1 = concatenate(list(map(lambda l: l(x1), [GlobalAvgPool1D(), GlobalMaxPool1D()])))\n",
    "    feat2 = concatenate(list(map(lambda l: l(x2), [GlobalAvgPool1D(), GlobalMaxPool1D()])))\n",
    "    feat3 = add([feat1, feat2])\n",
    "    feat4 = subtract([feat1, feat2])\n",
    "    feat5 = Lambda(lambda x: abs(x[0]-x[1]))([feat1, feat2])\n",
    "    x = Concatenate()([feat1, feat2]) #, feat4, feat3\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(dense_dim, activation=activation)(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(dense_dim, activation=activation)(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    return x\n",
    "\n",
    "def lstm_project_atten(q1_embed, q2_embed, projection_dim=100, projection_hidden=200, projection_dropout=0.2,\n",
    "                           compare_dim=500, compare_dropout=0.2,\n",
    "                           dense_dim=300, dropout_rate=0.2,\n",
    "                           lr=1e-3, activation='relu'):\n",
    "    \n",
    "    # CuDNN\n",
    "    lstm0 = CuDNNLSTM(model_params['num_lstm'],\n",
    "                 return_sequences = True)\n",
    "    lstm1 = Bidirectional(CuDNNLSTM(model_params['num_lstm'],\n",
    "                 return_sequences = True))\n",
    "    lstm2 = CuDNNLSTM(model_params['num_lstm'])\n",
    "    \n",
    "    att1 = Lambda(lambda x: K.max(x,axis = 1))\n",
    "    q1_embed = lstm1(q1_embed)\n",
    "    q2_embed = lstm1(q2_embed)\n",
    "    \n",
    "    # Projection\n",
    "    projection_layers = []\n",
    "#     if projection_hidden > 0:\n",
    "#         projection_layers.extend([\n",
    "#                 Dense(projection_hidden, activation=activation),\n",
    "#                 Dropout(rate=projection_dropout),\n",
    "#             ])\n",
    "#     projection_layers.extend([\n",
    "#             Dense(projection_dim, activation=None),\n",
    "#             Dropout(rate=projection_dropout),\n",
    "#         ])\n",
    "    q1_encoded = time_distributed(q1_embed, projection_layers)\n",
    "    q2_encoded = time_distributed(q2_embed, projection_layers)\n",
    "    \n",
    "    # Attention\n",
    "    q1_aligned, q2_aligned = align(q1_encoded, q2_encoded)  \n",
    "    \n",
    "    # Compare\n",
    "    q1_combined = concatenate([q1_encoded, q2_aligned])\n",
    "    q2_combined = concatenate([q2_encoded, q1_aligned]) \n",
    "#     compare_layers = [\n",
    "#         Dense(compare_dim, activation=None),\n",
    "#         Dropout(compare_dropout),\n",
    "#         Dense(compare_dim, activation=activation),\n",
    "#         Dropout(compare_dropout),\n",
    "#     ]\n",
    "    compare_layers = []\n",
    "    q1_compare = time_distributed(q1_combined, compare_layers)\n",
    "    q2_compare = time_distributed(q2_combined, compare_layers)\n",
    "    return q1_compare, q2_compare\n",
    "\n",
    "def build_model_combine(params, num_class=1,projection_dim=300, projection_hidden=200, projection_dropout=0.2,\n",
    "                           compare_dim=500, compare_dropout=0.2,\n",
    "                           dense_dim=300, dropout_rate=0.2,\n",
    "                           lr=1e-3, activation='relu'):\n",
    "    q1 = Input(name='q1',shape=(MAX_SEQUENCE_LENGTH_CHAR,), dtype='int32')\n",
    "    q2 = Input(name='q2',shape=(MAX_SEQUENCE_LENGTH_CHAR,), dtype='int32')\n",
    "    \n",
    "    q1_com = Input(name='q1_com',shape=(MAX_SEQUENCE_LENGTH_CHAR, 1), dtype='float32')\n",
    "    q2_com = Input(name='q2_com',shape=(MAX_SEQUENCE_LENGTH_CHAR, 1), dtype='float32')\n",
    "    \n",
    "    encode = Embedding(VOC_SIZE_CHAR, 300, input_length = MAX_SEQUENCE_LENGTH_CHAR,\n",
    "                       weights = [embedding_matrix_char], trainable=True) # \n",
    "    #encode0 = StaticEmbedding(embedding_matrix_char) #, encode0(q1), encode0(q2)\n",
    "    \n",
    "    # Word Representation Layer\n",
    "    q1_embed = concatenate([encode(q1), q1_com])\n",
    "    q2_embed = concatenate([encode(q2), q2_com])\n",
    "    \n",
    "    # Densely-connected Co-attentive networks\n",
    "    q1_compare0, q2_compare0 = lstm_project_atten(q1_embed, q2_embed)\n",
    "    \n",
    "    \n",
    "    q1_compare0 = concatenate([q1_compare0, q1_embed])\n",
    "    q2_compare0 = concatenate([q2_compare0, q2_embed])\n",
    "    \n",
    "    q1_compare1, q2_compare1 = lstm_project_atten(q1_compare0, q2_compare0)\n",
    "    \n",
    "    q1_compare1 = concatenate([q1_compare1, q1_compare0, q1_embed])\n",
    "    q2_compare1 = concatenate([q2_compare1, q2_compare0, q2_embed])\n",
    "    \n",
    "    q1_compare2, q2_compare2 = lstm_project_atten(q1_compare1, q2_compare1)\n",
    "    \n",
    "    \n",
    "    # Aggregate\n",
    "    x = aggregate_both(q1_compare1, q2_compare1, num_class)#, q10_compare1, q20_compare1\n",
    "    scores = Dense(num_class, activation='sigmoid')(x)\n",
    "    \n",
    "    model = Model(inputs=[q1, q2, q1_com, q2_com], outputs=scores)#\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1002</td>\n",
       "      <td>65 91 10 26 27 6 2 52 15 4 97 21 23 38 31 35</td>\n",
       "      <td>65 91 52 70 79 31 35 6 2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39267</td>\n",
       "      <td>3 2 83 48 242 58 35 229 15 4 65 91</td>\n",
       "      <td>15 4 105 83 242 58 35 229 3 2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3732</td>\n",
       "      <td>12 263 443 134 6 2 184 162 310 259 10</td>\n",
       "      <td>6 2 184 162 310 259 20 513 175 9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17937</td>\n",
       "      <td>24 17 4 40 59 38 7 9 3 2 5 12 18 383 340 51 11...</td>\n",
       "      <td>7 9 3 2 116 103 9 56 75 54 73 98 12 11 10 7 59...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6929</td>\n",
       "      <td>26 27 6 2 6 12 10 33</td>\n",
       "      <td>15 4 7 9 26 27 6 2 6 12 10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0                                                  1                                                  2  3\n",
       "0   1002       65 91 10 26 27 6 2 52 15 4 97 21 23 38 31 35                           65 91 52 70 79 31 35 6 2  1\n",
       "1  39267                 3 2 83 48 242 58 35 229 15 4 65 91                      15 4 105 83 242 58 35 229 3 2  1\n",
       "2   3732              12 263 443 134 6 2 184 162 310 259 10                   6 2 184 162 310 259 20 513 175 9  0\n",
       "3  17937  24 17 4 40 59 38 7 9 3 2 5 12 18 383 340 51 11...  7 9 3 2 116 103 9 56 75 54 73 98 12 11 10 7 59...  0\n",
       "4   6929                               26 27 6 2 6 12 10 33                         15 4 7 9 26 27 6 2 6 12 10  1"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_char_df = train_data_char\n",
    "train_data_char_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data_char_df = train_data_char_df.head(35000)\n",
    "word_squence_ques1_char = list(train_data_char_df.iloc[:, 1])\n",
    "word_squence_ques1_char = [[int(im) for im in item.split(' ')] for item in word_squence_ques1_char]\n",
    "word_squence_ques2_char = list(train_data_char_df.iloc[:, 2])\n",
    "word_squence_ques2_char = [[int(im) for im in item.split(' ')] for item in word_squence_ques2_char]\n",
    "\n",
    "# word_squence_ques1_word = list(train_data_word.iloc[:, 1])\n",
    "# word_squence_ques1_word = [[int(im) for im in item.split(' ')] for item in word_squence_ques1_word]\n",
    "# word_squence_ques2_word = list(train_data_word.iloc[:, 2])\n",
    "# word_squence_ques2_word = [[int(im) for im in item.split(' ')] for item in word_squence_ques2_word]\n",
    "\n",
    "\n",
    "MAX_SEQUENCE_LENGTH_WORD = 30 # char 40 word 30\n",
    "MAX_SEQUENCE_LENGTH_CHAR = 40 # char 40 word 30\n",
    "word_squence_ques1_char = pad_sequences(word_squence_ques1_char, maxlen=MAX_SEQUENCE_LENGTH_CHAR)\n",
    "word_squence_ques2_char = pad_sequences(word_squence_ques2_char, maxlen=MAX_SEQUENCE_LENGTH_CHAR)\n",
    "def cal_comman_sen(word_squence_ques1_char, word_squence_ques2_char):\n",
    "    comman_sen1 = []\n",
    "    comman_sen2 = []\n",
    "    for ques1, ques2 in zip(word_squence_ques1_char, word_squence_ques2_char):\n",
    "        comman_sen1.append([[1] if item in ques2 and item!=0 else [0] for item in ques1])\n",
    "        comman_sen2.append([[1] if item in ques1 and item!=0 else [0] for item in ques2])\n",
    "    return comman_sen1, comman_sen2\n",
    "comman_sen1, comman_sen2 = cal_comman_sen(word_squence_ques1_char, word_squence_ques2_char)\n",
    "# word_squence_ques1_word = pad_sequences(word_squence_ques1_word, maxlen=MAX_SEQUENCE_LENGTH_WORD)\n",
    "# word_squence_ques2_word = pad_sequences(word_squence_ques2_word, maxlen=MAX_SEQUENCE_LENGTH_WORD)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting fold\n",
      "Train on 89684 samples, validate on 9968 samples\n",
      "Epoch 1/100\n",
      "89684/89684 [==============================] - 71s 787us/step - loss: 0.5832 - acc: 0.6968 - val_loss: 0.5412 - val_acc: 0.7197\n",
      "('epoch end ', 0.1, ', f1-score: ', 0.9457987414732166, 'precision: ', 1.0, 'recall: ', 0.8971709470304976)\n",
      "('epoch end ', 0.15, ', f1-score: ', 0.9014162120460683, 'precision: ', 1.0, 'recall: ', 0.8205256821829856)\n",
      "('epoch end ', 0.2, ', f1-score: ', 0.8544503821180256, 'precision: ', 1.0, 'recall: ', 0.7458868378812199)\n",
      "('epoch end ', 0.25, ', f1-score: ', 0.8008421052631579, 'precision: ', 1.0, 'recall: ', 0.6678370786516854)\n",
      "('epoch end ', 0.3, ', f1-score: ', 0.7532207629768606, 'precision: ', 1.0, 'recall: ', 0.6041332263242376)\n",
      "('epoch end ', 0.35000000000000003, ', f1-score: ', 0.7021678276153895, 'precision: ', 1.0, 'recall: ', 0.5410313001605136)\n",
      "('epoch end ', 0.4, ', f1-score: ', 0.6468472137378674, 'precision: ', 1.0, 'recall: ', 0.47802969502407705)\n",
      "('epoch end ', 0.45, ', f1-score: ', 0.5879019691174387, 'precision: ', 1.0, 'recall: ', 0.4163322632423756)\n",
      "('epoch end ', 0.5, ', f1-score: ', 0.5278393147245606, 'precision: ', 1.0, 'recall: ', 0.3585473515248796)\n",
      "('epoch end ', 0.55, ', f1-score: ', 0.46279589791040177, 'precision: ', 1.0, 'recall: ', 0.3010634028892456)\n",
      "('epoch end ', 0.6, ', f1-score: ', 0.38927042094207004, 'precision: ', 1.0, 'recall: ', 0.2416733547351525)\n",
      "('epoch end ', 0.65, ', f1-score: ', 0.31350985534218767, 'precision: ', 1.0, 'recall: ', 0.1858948635634029)\n",
      "('epoch end ', 0.7000000000000001, ', f1-score: ', 0.2371562472367141, 'precision: ', 1.0, 'recall: ', 0.13453049759229535)\n",
      "('epoch end ', 0.75, ', f1-score: ', 0.16528621387815204, 'precision: ', 1.0, 'recall: ', 0.09008828250401284)\n",
      "('epoch end ', 0.8, ', f1-score: ', 0.09825431651244872, 'precision: ', 1.0, 'recall: ', 0.0516653290529695)\n",
      "('epoch end ', 0.85, ', f1-score: ', 0.042995975262589574, 'precision: ', 1.0, 'recall: ', 0.021970304975922953)\n",
      "Epoch 2/100\n",
      "89684/89684 [==============================] - 56s 624us/step - loss: 0.5139 - acc: 0.7488 - val_loss: 0.5414 - val_acc: 0.7221\n",
      "('epoch end ', 0.1, ', f1-score: ', 0.9511232703740726, 'precision: ', 1.0, 'recall: ', 0.9068017656500803)\n",
      "('epoch end ', 0.15, ', f1-score: ', 0.9164039569518425, 'precision: ', 1.0, 'recall: ', 0.8457062600321027)\n",
      "('epoch end ', 0.2, ', f1-score: ', 0.8803774008761092, 'precision: ', 1.0, 'recall: ', 0.7863162118780096)\n",
      "('epoch end ', 0.25, ', f1-score: ', 0.8422764227642277, 'precision: ', 1.0, 'recall: ', 0.7275280898876404)\n",
      "('epoch end ', 0.3, ', f1-score: ', 0.8034331672768742, 'precision: ', 1.0, 'recall: ', 0.6714486356340289)\n",
      "('epoch end ', 0.35000000000000003, ', f1-score: ', 0.7649609713790113, 'precision: ', 1.0, 'recall: ', 0.6193820224719101)\n",
      "('epoch end ', 0.4, ', f1-score: ', 0.7239326633809128, 'precision: ', 1.0, 'recall: ', 0.5673154093097913)\n",
      "('epoch end ', 0.45, ', f1-score: ', 0.6788601722995362, 'precision: ', 1.0, 'recall: ', 0.5138443017656501)\n",
      "('epoch end ', 0.5, ', f1-score: ', 0.630581123780739, 'precision: ', 1.0, 'recall: ', 0.46047351524879615)\n",
      "('epoch end ', 0.55, ', f1-score: ', 0.581168600099637, 'precision: ', 1.0, 'recall: ', 0.4096107544141252)\n",
      "('epoch end ', 0.6, ', f1-score: ', 0.5276218611521418, 'precision: ', 1.0, 'recall: ', 0.358346709470305)\n",
      "('epoch end ', 0.65, ', f1-score: ', 0.46657949388508574, 'precision: ', 1.0, 'recall: ', 0.3042736757624398)\n",
      "('epoch end ', 0.7000000000000001, ', f1-score: ', 0.3976852596045652, 'precision: ', 1.0, 'recall: ', 0.24819422150882825)\n",
      "('epoch end ', 0.75, ', f1-score: ', 0.3279375995974168, 'precision: ', 1.0, 'recall: ', 0.19612760834670948)\n",
      "('epoch end ', 0.8, ', f1-score: ', 0.25076774589804335, 'precision: ', 1.0, 'recall: ', 0.14335874799357945)\n",
      "('epoch end ', 0.85, ', f1-score: ', 0.1731879409878127, 'precision: ', 1.0, 'recall: ', 0.09480337078651685)\n",
      "Epoch 3/100\n",
      "89684/89684 [==============================] - 56s 627us/step - loss: 0.4746 - acc: 0.7724 - val_loss: 0.5117 - val_acc: 0.7524\n",
      "('epoch end ', 0.1, ', f1-score: ', 0.8271561360160018, 'precision: ', 1.0, 'recall: ', 0.7052568218298555)\n",
      "('epoch end ', 0.15, ', f1-score: ', 0.771884432945235, 'precision: ', 1.0, 'recall: ', 0.6285112359550562)\n",
      "('epoch end ', 0.2, ', f1-score: ', 0.7234424025100852, 'precision: ', 1.0, 'recall: ', 0.5667134831460674)\n",
      "('epoch end ', 0.25, ', f1-score: ', 0.6838317818709976, 'precision: ', 1.0, 'recall: ', 0.5195626003210273)\n",
      "('epoch end ', 0.3, ', f1-score: ', 0.6397379912663755, 'precision: ', 1.0, 'recall: ', 0.47030497592295345)\n",
      "('epoch end ', 0.35000000000000003, ', f1-score: ', 0.598523725834798, 'precision: ', 1.0, 'recall: ', 0.4270666131621188)\n",
      "('epoch end ', 0.4, ', f1-score: ', 0.5598497435526981, 'precision: ', 1.0, 'recall: ', 0.38874398073836275)\n",
      "('epoch end ', 0.45, ', f1-score: ', 0.5199703043801039, 'precision: ', 1.0, 'recall: ', 0.3513242375601926)\n",
      "('epoch end ', 0.5, ', f1-score: ', 0.47723800794378246, 'precision: ', 1.0, 'recall: ', 0.31340288924558585)\n",
      "('epoch end ', 0.55, ', f1-score: ', 0.4365147831542624, 'precision: ', 1.0, 'recall: ', 0.27919341894060995)\n",
      "('epoch end ', 0.6, ', f1-score: ', 0.38286826735885787, 'precision: ', 1.0, 'recall: ', 0.23675762439807382)\n",
      "('epoch end ', 0.65, ', f1-score: ', 0.32723611344185266, 'precision: ', 1.0, 'recall: ', 0.19562600321027288)\n",
      "('epoch end ', 0.7000000000000001, ', f1-score: ', 0.27259336279351876, 'precision: ', 1.0, 'recall: ', 0.15780497592295345)\n",
      "('epoch end ', 0.75, ', f1-score: ', 0.21329987452948554, 'precision: ', 1.0, 'recall: ', 0.11938202247191011)\n",
      "('epoch end ', 0.8, ', f1-score: ', 0.14996288047512993, 'precision: ', 1.0, 'recall: ', 0.08105939004815409)\n",
      "('epoch end ', 0.85, ', f1-score: ', 0.08326122488222286, 'precision: ', 1.0, 'recall: ', 0.04343900481540931)\n",
      "Epoch 4/100\n",
      "89684/89684 [==============================] - 56s 628us/step - loss: 0.4401 - acc: 0.7938 - val_loss: 0.5120 - val_acc: 0.7499\n",
      "('epoch end ', 0.1, ', f1-score: ', 0.8542528735632183, 'precision: ', 1.0, 'recall: ', 0.7455858747993579)\n",
      "('epoch end ', 0.15, ', f1-score: ', 0.8053691275167786, 'precision: ', 1.0, 'recall: ', 0.6741573033707865)\n",
      "('epoch end ', 0.2, ', f1-score: ', 0.7629684785306527, 'precision: ', 1.0, 'recall: ', 0.6167736757624398)\n",
      "('epoch end ', 0.25, ', f1-score: ', 0.7248304976333632, 'precision: ', 1.0, 'recall: ', 0.5684189406099518)\n",
      "('epoch end ', 0.3, ', f1-score: ', 0.6894556928740467, 'precision: ', 1.0, 'recall: ', 0.526083467094703)\n",
      "('epoch end ', 0.35000000000000003, ', f1-score: ', 0.6534278959810875, 'precision: ', 1.0, 'recall: ', 0.48525280898876405)\n",
      "('epoch end ', 0.4, ', f1-score: ', 0.615267069528374, 'precision: ', 1.0, 'recall: ', 0.4443218298555377)\n",
      "('epoch end ', 0.45, ', f1-score: ', 0.5762033995143551, 'precision: ', 1.0, 'recall: ', 0.40469502407704655)\n",
      "('epoch end ', 0.5, ', f1-score: ', 0.5331469354720035, 'precision: ', 1.0, 'recall: ', 0.36346308186195825)\n",
      "('epoch end ', 0.55, ', f1-score: ', 0.4891246684350133, 'precision: ', 1.0, 'recall: ', 0.3237359550561798)\n",
      "('epoch end ', 0.6, ', f1-score: ', 0.4421348753614129, 'precision: ', 1.0, 'recall: ', 0.28380818619582665)\n",
      "('epoch end ', 0.65, ', f1-score: ', 0.3875768359754124, 'precision: ', 1.0, 'recall: ', 0.24036918138041732)\n",
      "('epoch end ', 0.7000000000000001, ', f1-score: ', 0.3293388083466019, 'precision: ', 1.0, 'recall: ', 0.19713081861958268)\n",
      "('epoch end ', 0.75, ', f1-score: ', 0.26643478260869563, 'precision: ', 1.0, 'recall: ', 0.15369181380417335)\n",
      "('epoch end ', 0.8, ', f1-score: ', 0.2007220216606498, 'precision: ', 1.0, 'recall: ', 0.1115569823434992)\n",
      "('epoch end ', 0.85, ', f1-score: ', 0.12048647119826529, 'precision: ', 1.0, 'recall: ', 0.06410513643659711)\n",
      "Epoch 5/100\n",
      "89684/89684 [==============================] - 56s 628us/step - loss: 0.4016 - acc: 0.8165 - val_loss: 0.5366 - val_acc: 0.7519\n",
      "('epoch end ', 0.1, ', f1-score: ', 0.8030021014710298, 'precision: ', 1.0, 'recall: ', 0.670846709470305)\n",
      "('epoch end ', 0.15, ', f1-score: ', 0.759041394335512, 'precision: ', 1.0, 'recall: ', 0.6116573033707865)\n",
      "('epoch end ', 0.2, ', f1-score: ', 0.7229517647812439, 'precision: ', 1.0, 'recall: ', 0.5661115569823435)\n",
      "('epoch end ', 0.25, ', f1-score: ', 0.6914341975713817, 'precision: ', 1.0, 'recall: ', 0.5283908507223114)\n",
      "('epoch end ', 0.3, ', f1-score: ', 0.6611148421759571, 'precision: ', 1.0, 'recall: ', 0.4937800963081862)\n",
      "('epoch end ', 0.35000000000000003, ', f1-score: ', 0.6273753786835583, 'precision: ', 1.0, 'recall: ', 0.4570626003210273)\n",
      "('epoch end ', 0.4, ', f1-score: ', 0.5965505103836677, 'precision: ', 1.0, 'recall: ', 0.4250601926163724)\n",
      "('epoch end ', 0.45, ', f1-score: ', 0.5670955221735067, 'precision: ', 1.0, 'recall: ', 0.3957664526484751)\n",
      "('epoch end ', 0.5, ', f1-score: ', 0.5340098536657107, 'precision: ', 1.0, 'recall: ', 0.3642656500802568)\n",
      "('epoch end ', 0.55, ', f1-score: ', 0.4952826628424786, 'precision: ', 1.0, 'recall: ', 0.329153290529695)\n",
      "('epoch end ', 0.6, ', f1-score: ', 0.45815931941221966, 'precision: ', 1.0, 'recall: ', 0.29715088282504015)\n",
      "('epoch end ', 0.65, ', f1-score: ', 0.41827991113932084, 'precision: ', 1.0, 'recall: ', 0.264446227929374)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('epoch end ', 0.7000000000000001, ', f1-score: ', 0.37562128249001875, 'precision: ', 1.0, 'recall: ', 0.23123996789727128)\n",
      "('epoch end ', 0.75, ', f1-score: ', 0.328498365054079, 'precision: ', 1.0, 'recall: ', 0.19652889245585875)\n",
      "('epoch end ', 0.8, ', f1-score: ', 0.26568073075250104, 'precision: ', 1.0, 'recall: ', 0.15319020866773675)\n",
      "('epoch end ', 0.85, ', f1-score: ', 0.18763636363636363, 'precision: ', 1.0, 'recall: ', 0.10353130016051364)\n",
      "Epoch 6/100\n",
      "89684/89684 [==============================] - 56s 627us/step - loss: 0.3523 - acc: 0.8434 - val_loss: 0.5812 - val_acc: 0.7470\n",
      "('epoch end ', 0.1, ', f1-score: ', 0.7455323433173924, 'precision: ', 1.0, 'recall: ', 0.5943017656500803)\n",
      "('epoch end ', 0.15, ', f1-score: ', 0.7028433860368274, 'precision: ', 1.0, 'recall: ', 0.5418338683788122)\n",
      "('epoch end ', 0.2, ', f1-score: ', 0.6663990902401499, 'precision: ', 1.0, 'recall: ', 0.49969903691813805)\n",
      "('epoch end ', 0.25, ', f1-score: ', 0.6324598710385513, 'precision: ', 1.0, 'recall: ', 0.46247993579454255)\n",
      "('epoch end ', 0.3, ', f1-score: ', 0.6025515210991168, 'precision: ', 1.0, 'recall: ', 0.4311797752808989)\n",
      "('epoch end ', 0.35000000000000003, ', f1-score: ', 0.5704861609063531, 'precision: ', 1.0, 'recall: ', 0.39907704654895665)\n",
      "('epoch end ', 0.4, ', f1-score: ', 0.5407700190308886, 'precision: ', 1.0, 'recall: ', 0.37058587479935795)\n",
      "('epoch end ', 0.45, ', f1-score: ', 0.5115723458264895, 'precision: ', 1.0, 'recall: ', 0.34369983948635635)\n",
      "('epoch end ', 0.5, ', f1-score: ', 0.4809509295946358, 'precision: ', 1.0, 'recall: ', 0.3166131621187801)\n",
      "('epoch end ', 0.55, ', f1-score: ', 0.4461418550272798, 'precision: ', 1.0, 'recall: ', 0.2871187800963082)\n",
      "('epoch end ', 0.6, ', f1-score: ', 0.4095731950538492, 'precision: ', 1.0, 'recall: ', 0.25752407704654895)\n",
      "('epoch end ', 0.65, ', f1-score: ', 0.37190690077582683, 'precision: ', 1.0, 'recall: ', 0.22843097913322633)\n",
      "('epoch end ', 0.7000000000000001, ', f1-score: ', 0.32989863449778, 'precision: ', 1.0, 'recall: ', 0.19753210272873195)\n",
      "('epoch end ', 0.75, ', f1-score: ', 0.2837465564738292, 'precision: ', 1.0, 'recall: ', 0.1653290529695024)\n",
      "('epoch end ', 0.8, ', f1-score: ', 0.23058489393804915, 'precision: ', 1.0, 'recall: ', 0.13031701444622792)\n",
      "('epoch end ', 0.85, ', f1-score: ', 0.17335532343778634, 'precision: ', 1.0, 'recall: ', 0.09490369181380418)\n",
      "Epoch 7/100\n",
      "89684/89684 [==============================] - 56s 628us/step - loss: 0.2959 - acc: 0.8723 - val_loss: 0.6474 - val_acc: 0.7418\n",
      "('epoch end ', 0.1, ', f1-score: ', 0.765419866237305, 'precision: ', 1.0, 'recall: ', 0.619983948635634)\n",
      "('epoch end ', 0.15, ', f1-score: ', 0.7329350451252066, 'precision: ', 1.0, 'recall: ', 0.5784510433386838)\n",
      "('epoch end ', 0.2, ', f1-score: ', 0.7052864008312769, 'precision: ', 1.0, 'recall: ', 0.5447431781701445)\n",
      "('epoch end ', 0.25, ', f1-score: ', 0.6826141544967951, 'precision: ', 1.0, 'recall: ', 0.5181581059390048)\n",
      "('epoch end ', 0.3, ', f1-score: ', 0.6583215559593513, 'precision: ', 1.0, 'recall: ', 0.4906701444622793)\n",
      "('epoch end ', 0.35000000000000003, ', f1-score: ', 0.6367614879649891, 'precision: ', 1.0, 'recall: ', 0.46709470304975925)\n",
      "('epoch end ', 0.4, ', f1-score: ', 0.617763294737572, 'precision: ', 1.0, 'recall: ', 0.44693017656500805)\n",
      "('epoch end ', 0.45, ', f1-score: ', 0.596056338028169, 'precision: ', 1.0, 'recall: ', 0.4245585874799358)\n",
      "('epoch end ', 0.5, ', f1-score: ', 0.5757965423631948, 'precision: ', 1.0, 'recall: ', 0.40429373996789725)\n",
      "('epoch end ', 0.55, ', f1-score: ', 0.5565129244804865, 'precision: ', 1.0, 'recall: ', 0.38553370786516855)\n",
      "('epoch end ', 0.6, ', f1-score: ', 0.5320668581105957, 'precision: ', 1.0, 'recall: ', 0.36245987158908505)\n",
      "('epoch end ', 0.65, ', f1-score: ', 0.5065547981122182, 'precision: ', 1.0, 'recall: ', 0.33918539325842695)\n",
      "('epoch end ', 0.7000000000000001, ', f1-score: ', 0.47805175967631114, 'precision: ', 1.0, 'recall: ', 0.3141051364365971)\n",
      "('epoch end ', 0.75, ', f1-score: ', 0.43908549953022236, 'precision: ', 1.0, 'recall: ', 0.28130016051364365)\n",
      "('epoch end ', 0.8, ', f1-score: ', 0.39147974826528964, 'precision: ', 1.0, 'recall: ', 0.24337881219903693)\n",
      "('epoch end ', 0.85, ', f1-score: ', 0.3314362236357549, 'precision: ', 1.0, 'recall: ', 0.19863563402889245)\n",
      "Epoch 8/100\n",
      "89684/89684 [==============================] - 56s 628us/step - loss: 0.2417 - acc: 0.8980 - val_loss: 0.8123 - val_acc: 0.7511\n",
      "('epoch end ', 0.1, ', f1-score: ', 0.6588631012445342, 'precision: ', 1.0, 'recall: ', 0.4912720706260032)\n",
      "('epoch end ', 0.15, ', f1-score: ', 0.632553673091433, 'precision: ', 1.0, 'recall: ', 0.46258025682182985)\n",
      "('epoch end ', 0.2, ', f1-score: ', 0.6112156043190525, 'precision: ', 1.0, 'recall: ', 0.4401083467094703)\n",
      "('epoch end ', 0.25, ', f1-score: ', 0.5952649379932357, 'precision: ', 1.0, 'recall: ', 0.42375601926163725)\n",
      "('epoch end ', 0.3, ', f1-score: ', 0.5763050774833964, 'precision: ', 1.0, 'recall: ', 0.40479534510433385)\n",
      "('epoch end ', 0.35000000000000003, ', f1-score: ', 0.5616161616161617, 'precision: ', 1.0, 'recall: ', 0.3904494382022472)\n",
      "('epoch end ', 0.4, ', f1-score: ', 0.546409041195771, 'precision: ', 1.0, 'recall: ', 0.37590288924558585)\n",
      "('epoch end ', 0.45, ', f1-score: ', 0.5303354220420199, 'precision: ', 1.0, 'recall: ', 0.36085473515248795)\n",
      "('epoch end ', 0.5, ', f1-score: ', 0.5121277707291589, 'precision: ', 1.0, 'recall: ', 0.34420144462279295)\n",
      "('epoch end ', 0.55, ', f1-score: ', 0.49243799153055057, 'precision: ', 1.0, 'recall: ', 0.32664526484751205)\n",
      "('epoch end ', 0.6, ', f1-score: ', 0.47420786774835444, 'precision: ', 1.0, 'recall: ', 0.31079454253611555)\n",
      "('epoch end ', 0.65, ', f1-score: ', 0.4556510961344798, 'precision: ', 1.0, 'recall: ', 0.2950441412520064)\n",
      "('epoch end ', 0.7000000000000001, ', f1-score: ', 0.4344275168839327, 'precision: ', 1.0, 'recall: ', 0.2774879614767255)\n",
      "('epoch end ', 0.75, ', f1-score: ', 0.40703156212544944, 'precision: ', 1.0, 'recall: ', 0.25551765650080255)\n",
      "('epoch end ', 0.8, ', f1-score: ', 0.378527856852379, 'precision: ', 1.0, 'recall: ', 0.2334470304975923)\n",
      "('epoch end ', 0.85, ', f1-score: ', 0.34074074074074073, 'precision: ', 1.0, 'recall: ', 0.20535714285714285)\n",
      "Epoch 9/100\n",
      "89684/89684 [==============================] - 56s 626us/step - loss: 0.1495 - acc: 0.9435 - val_loss: 0.8180 - val_acc: 0.7448\n",
      "('epoch end ', 0.1, ', f1-score: ', 0.6899724011039559, 'precision: ', 1.0, 'recall: ', 0.526685393258427)\n",
      "('epoch end ', 0.15, ', f1-score: ', 0.6641651031894934, 'precision: ', 1.0, 'recall: ', 0.49719101123595505)\n",
      "('epoch end ', 0.2, ', f1-score: ', 0.6462959190602295, 'precision: ', 1.0, 'recall: ', 0.47742776886035315)\n",
      "('epoch end ', 0.25, ', f1-score: ', 0.6286028754213386, 'precision: ', 1.0, 'recall: ', 0.45836677367576245)\n",
      "('epoch end ', 0.3, ', f1-score: ', 0.6137264446144218, 'precision: ', 1.0, 'recall: ', 0.4427166934189406)\n",
      "('epoch end ', 0.35000000000000003, ', f1-score: ', 0.5997049940296411, 'precision: ', 1.0, 'recall: ', 0.4282704654895666)\n",
      "('epoch end ', 0.4, ', f1-score: ', 0.5855977296913799, 'precision: ', 1.0, 'recall: ', 0.41402487961476725)\n",
      "('epoch end ', 0.45, ', f1-score: ', 0.5716128107759547, 'precision: ', 1.0, 'recall: ', 0.40018057784911715)\n",
      "('epoch end ', 0.5, ', f1-score: ', 0.5557809330628803, 'precision: ', 1.0, 'recall: ', 0.3848314606741573)\n",
      "('epoch end ', 0.55, ', f1-score: ', 0.5378804547121379, 'precision: ', 1.0, 'recall: ', 0.3678772070626003)\n",
      "('epoch end ', 0.6, ', f1-score: ', 0.5215069712251557, 'precision: ', 1.0, 'recall: ', 0.3527287319422151)\n",
      "('epoch end ', 0.65, ', f1-score: ', 0.5047626190654767, 'precision: ', 1.0, 'recall: ', 0.33758025682182985)\n",
      "('epoch end ', 0.7000000000000001, ', f1-score: ', 0.4840696524979089, 'precision: ', 1.0, 'recall: ', 0.3193218298555377)\n",
      "('epoch end ', 0.75, ', f1-score: ', 0.46065940853988113, 'precision: ', 1.0, 'recall: ', 0.29925762439807385)\n",
      "('epoch end ', 0.8, ', f1-score: ', 0.4340585971251276, 'precision: ', 1.0, 'recall: ', 0.27718699839486355)\n",
      "('epoch end ', 0.85, ', f1-score: ', 0.40179573512906847, 'precision: ', 1.0, 'recall: ', 0.25140449438202245)\n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89684/89684 [==============================] - 56s 629us/step - loss: 0.1133 - acc: 0.9580 - val_loss: 0.9219 - val_acc: 0.7421\n",
      "('epoch end ', 0.1, ', f1-score: ', 0.6696029362696029, 'precision: ', 1.0, 'recall: ', 0.5033105939004815)\n",
      "('epoch end ', 0.15, ', f1-score: ', 0.6495054870613738, 'precision: ', 1.0, 'recall: ', 0.4809390048154093)\n",
      "('epoch end ', 0.2, ', f1-score: ', 0.630957286087076, 'precision: ', 1.0, 'recall: ', 0.46087479935794545)\n",
      "('epoch end ', 0.25, ', f1-score: ', 0.6149784632485757, 'precision: ', 1.0, 'recall: ', 0.44402086677367575)\n",
      "('epoch end ', 0.3, ', f1-score: ', 0.601080625920988, 'precision: ', 1.0, 'recall: ', 0.4296749598715891)\n",
      "('epoch end ', 0.35000000000000003, ', f1-score: ', 0.5882019686991006, 'precision: ', 1.0, 'recall: ', 0.41663322632423755)\n",
      "('epoch end ', 0.4, ', f1-score: ', 0.5746764853077858, 'precision: ', 1.0, 'recall: ', 0.40319020866773675)\n",
      "('epoch end ', 0.45, ', f1-score: ', 0.5605776173285199, 'precision: ', 1.0, 'recall: ', 0.389446227929374)\n",
      "('epoch end ', 0.5, ', f1-score: ', 0.5470446760440201, 'precision: ', 1.0, 'recall: ', 0.3765048154093098)\n",
      "('epoch end ', 0.55, ', f1-score: ', 0.533578521515263, 'precision: ', 1.0, 'recall: ', 0.36386436597110755)\n",
      "('epoch end ', 0.6, ', f1-score: ', 0.5195306698351403, 'precision: ', 1.0, 'recall: ', 0.35092295345104335)\n",
      "('epoch end ', 0.65, ', f1-score: ', 0.5048747562621868, 'precision: ', 1.0, 'recall: ', 0.33768057784911715)\n",
      "('epoch end ', 0.7000000000000001, ', f1-score: ', 0.4872903862205023, 'precision: ', 1.0, 'recall: ', 0.32213081861958265)\n",
      "('epoch end ', 0.75, ', f1-score: ', 0.469404990403071, 'precision: ', 1.0, 'recall: ', 0.30668138041733545)\n",
      "('epoch end ', 0.8, ', f1-score: ', 0.4461418550272798, 'precision: ', 1.0, 'recall: ', 0.2871187800963082)\n",
      "('epoch end ', 0.85, ', f1-score: ', 0.4196591359492668, 'precision: ', 1.0, 'recall: ', 0.2655497592295345)\n",
      "Epoch 11/100\n",
      "89684/89684 [==============================] - 56s 629us/step - loss: 0.0946 - acc: 0.9660 - val_loss: 1.0126 - val_acc: 0.7428\n",
      "('epoch end ', 0.1, ', f1-score: ', 0.6575988148946199, 'precision: ', 1.0, 'recall: ', 0.48986757624398075)\n",
      "('epoch end ', 0.15, ', f1-score: ', 0.6390879923544269, 'precision: ', 1.0, 'recall: ', 0.4696027287319422)\n",
      "('epoch end ', 0.2, ', f1-score: ', 0.6217767023850674, 'precision: ', 1.0, 'recall: ', 0.45114365971107545)\n",
      "('epoch end ', 0.25, ', f1-score: ', 0.6067509958767209, 'precision: ', 1.0, 'recall: ', 0.4354935794542536)\n",
      "('epoch end ', 0.3, ', f1-score: ', 0.5958585716298069, 'precision: ', 1.0, 'recall: ', 0.42435794542536115)\n",
      "('epoch end ', 0.35000000000000003, ', f1-score: ', 0.583587921847247, 'precision: ', 1.0, 'recall: ', 0.41201845906902085)\n",
      "('epoch end ', 0.4, ', f1-score: ', 0.5711009174311927, 'precision: ', 1.0, 'recall: ', 0.3996789727126806)\n",
      "('epoch end ', 0.45, ', f1-score: ', 0.5592252655922527, 'precision: ', 1.0, 'recall: ', 0.38814205457463885)\n",
      "('epoch end ', 0.5, ', f1-score: ', 0.5482085639382464, 'precision: ', 1.0, 'recall: ', 0.3776083467094703)\n",
      "('epoch end ', 0.55, ', f1-score: ', 0.537451397549703, 'precision: ', 1.0, 'recall: ', 0.36747592295345105)\n",
      "('epoch end ', 0.6, ', f1-score: ', 0.5245707519242155, 'precision: ', 1.0, 'recall: ', 0.35553772070626005)\n",
      "('epoch end ', 0.65, ', f1-score: ', 0.5092350257982502, 'precision: ', 1.0, 'recall: ', 0.34159309791332265)\n",
      "('epoch end ', 0.7000000000000001, ', f1-score: ', 0.4928938615058966, 'precision: ', 1.0, 'recall: ', 0.3270465489566613)\n",
      "('epoch end ', 0.75, ', f1-score: ', 0.4779355626813254, 'precision: ', 1.0, 'recall: ', 0.3140048154093098)\n",
      "('epoch end ', 0.8, ', f1-score: ', 0.45946990186229814, 'precision: ', 1.0, 'recall: ', 0.29825441412520065)\n",
      "('epoch end ', 0.85, ', f1-score: ', 0.43479626285624556, 'precision: ', 1.0, 'recall: ', 0.2777889245585875)\n",
      "Epoch 12/100\n",
      "89684/89684 [==============================] - 56s 628us/step - loss: 0.0783 - acc: 0.9718 - val_loss: 1.1115 - val_acc: 0.7387\n",
      "('epoch end ', 0.1, ', f1-score: ', 0.6445471852053305, 'precision: ', 1.0, 'recall: ', 0.47552166934189405)\n",
      "('epoch end ', 0.15, ', f1-score: ', 0.6249137812112016, 'precision: ', 1.0, 'recall: ', 0.454454253611557)\n",
      "('epoch end ', 0.2, ', f1-score: ', 0.6087927424982554, 'precision: ', 1.0, 'recall: ', 0.4376003210272873)\n",
      "('epoch end ', 0.25, ', f1-score: ', 0.5972417675204054, 'precision: ', 1.0, 'recall: ', 0.42576243980738365)\n",
      "('epoch end ', 0.3, ', f1-score: ', 0.584694022433622, 'precision: ', 1.0, 'recall: ', 0.4131219903691814)\n",
      "('epoch end ', 0.35000000000000003, ', f1-score: ', 0.5724310776942356, 'precision: ', 1.0, 'recall: ', 0.40098314606741575)\n",
      "('epoch end ', 0.4, ', f1-score: ', 0.5623422513881878, 'precision: ', 1.0, 'recall: ', 0.39115168539325845)\n",
      "('epoch end ', 0.45, ', f1-score: ', 0.549476135040745, 'precision: ', 1.0, 'recall: ', 0.37881219903691815)\n",
      "('epoch end ', 0.5, ', f1-score: ', 0.5400219699743684, 'precision: ', 1.0, 'recall: ', 0.3698836276083467)\n",
      "('epoch end ', 0.55, ', f1-score: ', 0.5290341621781155, 'precision: ', 1.0, 'recall: ', 0.35965088282504015)\n",
      "('epoch end ', 0.6, ', f1-score: ', 0.5165562913907285, 'precision: ', 1.0, 'recall: ', 0.3482142857142857)\n",
      "('epoch end ', 0.65, ', f1-score: ', 0.5020662709444736, 'precision: ', 1.0, 'recall: ', 0.3351725521669342)\n",
      "('epoch end ', 0.7000000000000001, ', f1-score: ', 0.48797876374668187, 'precision: ', 1.0, 'recall: ', 0.3227327447833066)\n",
      "('epoch end ', 0.75, ', f1-score: ', 0.4721030042918455, 'precision: ', 1.0, 'recall: ', 0.3089887640449438)\n",
      "('epoch end ', 0.8, ', f1-score: ', 0.4564880768039641, 'precision: ', 1.0, 'recall: ', 0.29574638844301765)\n",
      "('epoch end ', 0.85, ', f1-score: ', 0.4344275168839327, 'precision: ', 1.0, 'recall: ', 0.2774879614767255)\n",
      "Epoch 13/100\n",
      "89684/89684 [==============================] - 56s 627us/step - loss: 0.0662 - acc: 0.9761 - val_loss: 1.2328 - val_acc: 0.7389\n",
      "('epoch end ', 0.1, ', f1-score: ', 0.6192949650252787, 'precision: ', 1.0, 'recall: ', 0.44853531300160515)\n",
      "('epoch end ', 0.15, ', f1-score: ', 0.6005896391969676, 'precision: ', 1.0, 'recall: ', 0.4291733547351525)\n",
      "('epoch end ', 0.2, ', f1-score: ', 0.5865002836074872, 'precision: ', 1.0, 'recall: ', 0.41492776886035315)\n",
      "('epoch end ', 0.25, ', f1-score: ', 0.5734525939177102, 'precision: ', 1.0, 'recall: ', 0.4019863563402889)\n",
      "('epoch end ', 0.3, ', f1-score: ', 0.5615123746302042, 'precision: ', 1.0, 'recall: ', 0.39034911717495985)\n",
      "('epoch end ', 0.35000000000000003, ', f1-score: ', 0.5506361323155217, 'precision: ', 1.0, 'recall: ', 0.37991573033707865)\n",
      "('epoch end ', 0.4, ', f1-score: ', 0.540663201815387, 'precision: ', 1.0, 'recall: ', 0.37048555377207065)\n",
      "('epoch end ', 0.45, ', f1-score: ', 0.5308769344141488, 'precision: ', 1.0, 'recall: ', 0.36135634028892455)\n",
      "('epoch end ', 0.5, ', f1-score: ', 0.5207390368776434, 'precision: ', 1.0, 'recall: ', 0.35202648475120385)\n",
      "('epoch end ', 0.55, ', f1-score: ', 0.5116834639790967, 'precision: ', 1.0, 'recall: ', 0.34380016051364365)\n",
      "('epoch end ', 0.6, ', f1-score: ', 0.5017285435142042, 'precision: ', 1.0, 'recall: ', 0.33487158908507225)\n",
      "('epoch end ', 0.65, ', f1-score: ', 0.49004014239188065, 'precision: ', 1.0, 'recall: ', 0.32453852327447835)\n",
      "('epoch end ', 0.7000000000000001, ', f1-score: ', 0.478400244237521, 'precision: ', 1.0, 'recall: ', 0.31440609951845905)\n",
      "('epoch end ', 0.75, ', f1-score: ', 0.4637435462741774, 'precision: ', 1.0, 'recall: ', 0.30186597110754415)\n",
      "('epoch end ', 0.8, ', f1-score: ', 0.44880174291938996, 'precision: ', 1.0, 'recall: ', 0.2893258426966292)\n",
      "('epoch end ', 0.85, ', f1-score: ', 0.429123000551572, 'precision: ', 1.0, 'recall: ', 0.2731741573033708)\n",
      "Epoch 14/100\n",
      "89684/89684 [==============================] - 56s 629us/step - loss: 0.0537 - acc: 0.9819 - val_loss: 1.2291 - val_acc: 0.7388\n",
      "('epoch end ', 0.1, ', f1-score: ', 0.6317089910775566, 'precision: ', 1.0, 'recall: ', 0.461677367576244)\n",
      "('epoch end ', 0.15, ', f1-score: ', 0.614208258028639, 'precision: ', 1.0, 'recall: ', 0.4432182985553772)\n",
      "('epoch end ', 0.2, ', f1-score: ', 0.5991146089522872, 'precision: ', 1.0, 'recall: ', 0.4276685393258427)\n",
      "('epoch end ', 0.25, ', f1-score: ', 0.5879019691174387, 'precision: ', 1.0, 'recall: ', 0.4163322632423756)\n",
      "('epoch end ', 0.3, ', f1-score: ', 0.5781328007988018, 'precision: ', 1.0, 'recall: ', 0.4066011235955056)\n",
      "('epoch end ', 0.35000000000000003, ', f1-score: ', 0.5687414746212938, 'precision: ', 1.0, 'recall: ', 0.39737158908507225)\n",
      "('epoch end ', 0.4, ', f1-score: ', 0.5580789816288153, 'precision: ', 1.0, 'recall: ', 0.38703852327447835)\n",
      "('epoch end ', 0.45, ', f1-score: ', 0.5473622850480909, 'precision: ', 1.0, 'recall: ', 0.37680577849117175)\n",
      "('epoch end ', 0.5, ', f1-score: ', 0.5382020824167766, 'precision: ', 1.0, 'recall: ', 0.3681781701444623)\n",
      "('epoch end ', 0.55, ', f1-score: ', 0.5285998966713411, 'precision: ', 1.0, 'recall: ', 0.35924959871589085)\n",
      "('epoch end ', 0.6, ', f1-score: ', 0.5187606805854819, 'precision: ', 1.0, 'recall: ', 0.3502207062600321)\n",
      "('epoch end ', 0.65, ', f1-score: ', 0.5068903535050929, 'precision: ', 1.0, 'recall: ', 0.3394863563402889)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('epoch end ', 0.7000000000000001, ', f1-score: ', 0.4943735367419379, 'precision: ', 1.0, 'recall: ', 0.32835072231139645)\n",
      "('epoch end ', 0.75, ', f1-score: ', 0.4811823861039159, 'precision: ', 1.0, 'recall: ', 0.31681380417335475)\n",
      "('epoch end ', 0.8, ', f1-score: ', 0.4663435648896069, 'precision: ', 1.0, 'recall: ', 0.30407303370786515)\n",
      "('epoch end ', 0.85, ', f1-score: ', 0.4456572586932793, 'precision: ', 1.0, 'recall: ', 0.2867174959871589)\n",
      "Epoch 15/100\n",
      "89684/89684 [==============================] - 56s 627us/step - loss: 0.0521 - acc: 0.9824 - val_loss: 1.2434 - val_acc: 0.7386\n",
      "('epoch end ', 0.1, ', f1-score: ', 0.6303929651003022, 'precision: ', 1.0, 'recall: ', 0.4602728731942215)\n",
      "('epoch end ', 0.15, ', f1-score: ', 0.6129548458916023, 'precision: ', 1.0, 'recall: ', 0.44191412520064205)\n",
      "('epoch end ', 0.2, ', f1-score: ', 0.599213041034289, 'precision: ', 1.0, 'recall: ', 0.42776886035313)\n",
      "('epoch end ', 0.25, ', f1-score: ', 0.5876018420120439, 'precision: ', 1.0, 'recall: ', 0.41603130016051365)\n",
      "('epoch end ', 0.3, ', f1-score: ', 0.579449907367821, 'precision: ', 1.0, 'recall: ', 0.40790529695024075)\n",
      "('epoch end ', 0.35000000000000003, ', f1-score: ', 0.5678160919540229, 'precision: ', 1.0, 'recall: ', 0.39646869983948635)\n",
      "('epoch end ', 0.4, ', f1-score: ', 0.5569308722403185, 'precision: ', 1.0, 'recall: ', 0.3859349919743178)\n",
      "('epoch end ', 0.45, ', f1-score: ', 0.5477855477855479, 'precision: ', 1.0, 'recall: ', 0.37720706260032105)\n",
      "('epoch end ', 0.5, ', f1-score: ', 0.5390590649274513, 'precision: ', 1.0, 'recall: ', 0.36898073836276085)\n",
      "('epoch end ', 0.55, ', f1-score: ', 0.5289256198347108, 'precision: ', 1.0, 'recall: ', 0.3595505617977528)\n",
      "('epoch end ', 0.6, ', f1-score: ', 0.5183203270159792, 'precision: ', 1.0, 'recall: ', 0.34981942215088285)\n",
      "('epoch end ', 0.65, ', f1-score: ', 0.5063310107140181, 'precision: ', 1.0, 'recall: ', 0.33898475120385235)\n",
      "('epoch end ', 0.7000000000000001, ', f1-score: ', 0.4958503093405764, 'precision: ', 1.0, 'recall: ', 0.3296548956661316)\n",
      "('epoch end ', 0.75, ', f1-score: ', 0.4838390752148452, 'precision: ', 1.0, 'recall: ', 0.3191211878009631)\n",
      "('epoch end ', 0.8, ', f1-score: ', 0.46752248443385347, 'precision: ', 1.0, 'recall: ', 0.30507624398073835)\n",
      "('epoch end ', 0.85, ', f1-score: ', 0.4480772224817064, 'precision: ', 1.0, 'recall: ', 0.2887239165329053)\n",
      "Epoch 16/100\n",
      "89684/89684 [==============================] - 56s 628us/step - loss: 0.0505 - acc: 0.9829 - val_loss: 1.2593 - val_acc: 0.7395\n",
      "('epoch end ', 0.1, ', f1-score: ', 0.6324598710385513, 'precision: ', 1.0, 'recall: ', 0.46247993579454255)\n",
      "('epoch end ', 0.15, ', f1-score: ', 0.6158439214052628, 'precision: ', 1.0, 'recall: ', 0.44492375601926165)\n",
      "('epoch end ', 0.2, ', f1-score: ', 0.602453557658605, 'precision: ', 1.0, 'recall: ', 0.43107945425361155)\n",
      "('epoch end ', 0.25, ', f1-score: ', 0.5909958300939996, 'precision: ', 1.0, 'recall: ', 0.4194422150882825)\n",
      "('epoch end ', 0.3, ', f1-score: ', 0.581168600099637, 'precision: ', 1.0, 'recall: ', 0.4096107544141252)\n",
      "('epoch end ', 0.35000000000000003, ', f1-score: ', 0.5712033254497241, 'precision: ', 1.0, 'recall: ', 0.3997792937399679)\n",
      "('epoch end ', 0.4, ', f1-score: ', 0.5618236906651277, 'precision: ', 1.0, 'recall: ', 0.39065008025682185)\n",
      "('epoch end ', 0.45, ', f1-score: ', 0.5521098118962887, 'precision: ', 1.0, 'recall: ', 0.3813202247191011)\n",
      "('epoch end ', 0.5, ', f1-score: ', 0.5438609305383099, 'precision: ', 1.0, 'recall: ', 0.3734951845906902)\n",
      "('epoch end ', 0.55, ', f1-score: ', 0.5343331862961329, 'precision: ', 1.0, 'recall: ', 0.3645666131621188)\n",
      "('epoch end ', 0.6, ', f1-score: ', 0.5235873509590461, 'precision: ', 1.0, 'recall: ', 0.35463483146067415)\n",
      "('epoch end ', 0.65, ', f1-score: ', 0.5124608267422773, 'precision: ', 1.0, 'recall: ', 0.3445024077046549)\n",
      "('epoch end ', 0.7000000000000001, ', f1-score: ', 0.5004889056036104, 'precision: ', 1.0, 'recall: ', 0.3337680577849117)\n",
      "('epoch end ', 0.75, ', f1-score: ', 0.49004014239188065, 'precision: ', 1.0, 'recall: ', 0.32453852327447835)\n",
      "('epoch end ', 0.8, ', f1-score: ', 0.4736237654084679, 'precision: ', 1.0, 'recall: ', 0.31029293739967895)\n",
      "('epoch end ', 0.85, ', f1-score: ', 0.4548132072546892, 'precision: ', 1.0, 'recall: ', 0.2943418940609952)\n",
      "Epoch 17/100\n",
      "89684/89684 [==============================] - 56s 629us/step - loss: 0.0486 - acc: 0.9838 - val_loss: 1.2733 - val_acc: 0.7376\n",
      "('epoch end ', 0.1, ', f1-score: ', 0.627564367341319, 'precision: ', 1.0, 'recall: ', 0.45726324237560195)\n",
      "('epoch end ', 0.15, ', f1-score: ', 0.6104412072210218, 'precision: ', 1.0, 'recall: ', 0.43930577849117175)\n",
      "('epoch end ', 0.2, ', f1-score: ', 0.5961552003380043, 'precision: ', 1.0, 'recall: ', 0.4246589085072231)\n",
      "('epoch end ', 0.25, ', f1-score: ', 0.5850958126330731, 'precision: ', 1.0, 'recall: ', 0.41352327447833065)\n",
      "('epoch end ', 0.3, ', f1-score: ', 0.575287643821911, 'precision: ', 1.0, 'recall: ', 0.40379213483146065)\n",
      "('epoch end ', 0.35000000000000003, ', f1-score: ', 0.5652392947103274, 'precision: ', 1.0, 'recall: ', 0.39396067415730335)\n",
      "('epoch end ', 0.4, ', f1-score: ', 0.5554669951452793, 'precision: ', 1.0, 'recall: ', 0.38453049759229535)\n",
      "('epoch end ', 0.45, ', f1-score: ', 0.545560662435252, 'precision: ', 1.0, 'recall: ', 0.3751003210272873)\n",
      "('epoch end ', 0.5, ', f1-score: ', 0.535840188014101, 'precision: ', 1.0, 'recall: ', 0.36597110754414125)\n",
      "('epoch end ', 0.55, ', f1-score: ', 0.5272955603161704, 'precision: ', 1.0, 'recall: ', 0.358045746388443)\n",
      "('epoch end ', 0.6, ', f1-score: ', 0.5152305056974752, 'precision: ', 1.0, 'recall: ', 0.3470104333868379)\n",
      "('epoch end ', 0.65, ', f1-score: ', 0.5054351900442312, 'precision: ', 1.0, 'recall: ', 0.33818218298555375)\n",
      "('epoch end ', 0.7000000000000001, ', f1-score: ', 0.4943735367419379, 'precision: ', 1.0, 'recall: ', 0.32835072231139645)\n",
      "('epoch end ', 0.75, ', f1-score: ', 0.4833777101559528, 'precision: ', 1.0, 'recall: ', 0.3187199036918138)\n",
      "('epoch end ', 0.8, ', f1-score: ', 0.46846431589459936, 'precision: ', 1.0, 'recall: ', 0.3058788121990369)\n",
      "('epoch end ', 0.85, ', f1-score: ', 0.45000777484061577, 'precision: ', 1.0, 'recall: ', 0.2903290529695024)\n",
      "Epoch 18/100\n",
      "89684/89684 [==============================] - 56s 628us/step - loss: 0.0475 - acc: 0.9839 - val_loss: 1.2908 - val_acc: 0.7386\n",
      "('epoch end ', 0.1, ', f1-score: ', 0.6245342900510557, 'precision: ', 1.0, 'recall: ', 0.4540529695024077)\n",
      "('epoch end ', 0.15, ', f1-score: ', 0.6074322436434758, 'precision: ', 1.0, 'recall: ', 0.43619582664526485)\n",
      "('epoch end ', 0.2, ', f1-score: ', 0.5946708021993515, 'precision: ', 1.0, 'recall: ', 0.4231540930979133)\n",
      "('epoch end ', 0.25, ', f1-score: ', 0.5848949460533788, 'precision: ', 1.0, 'recall: ', 0.413322632423756)\n",
      "('epoch end ', 0.3, ', f1-score: ', 0.5742687549166845, 'precision: ', 1.0, 'recall: ', 0.4027889245585875)\n",
      "('epoch end ', 0.35000000000000003, ', f1-score: ', 0.5644127601353784, 'precision: ', 1.0, 'recall: ', 0.3931581059390048)\n",
      "('epoch end ', 0.4, ', f1-score: ', 0.5554669951452793, 'precision: ', 1.0, 'recall: ', 0.38453049759229535)\n",
      "('epoch end ', 0.45, ', f1-score: ', 0.5450299226390307, 'precision: ', 1.0, 'recall: ', 0.3745987158908507)\n",
      "('epoch end ', 0.5, ', f1-score: ', 0.5354099324125771, 'precision: ', 1.0, 'recall: ', 0.36556982343499195)\n",
      "('epoch end ', 0.55, ', f1-score: ', 0.5265336289726534, 'precision: ', 1.0, 'recall: ', 0.3573434991974318)\n",
      "('epoch end ', 0.6, ', f1-score: ', 0.5158936946326211, 'precision: ', 1.0, 'recall: ', 0.3476123595505618)\n",
      "('epoch end ', 0.65, ', f1-score: ', 0.5062190918627304, 'precision: ', 1.0, 'recall: ', 0.338884430176565)\n",
      "('epoch end ', 0.7000000000000001, ', f1-score: ', 0.49460092124141053, 'precision: ', 1.0, 'recall: ', 0.3285513643659711)\n",
      "('epoch end ', 0.75, ', f1-score: ', 0.48395437262357416, 'precision: ', 1.0, 'recall: ', 0.3192215088282504)\n",
      "('epoch end ', 0.8, ', f1-score: ', 0.46916993012362745, 'precision: ', 1.0, 'recall: ', 0.30648073836276085)\n",
      "('epoch end ', 0.85, ', f1-score: ', 0.4502487562189055, 'precision: ', 1.0, 'recall: ', 0.29052969502407705)\n",
      "Epoch 19/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89684/89684 [==============================] - 56s 627us/step - loss: 0.0462 - acc: 0.9843 - val_loss: 1.2906 - val_acc: 0.7390\n",
      "('epoch end ', 0.1, ', f1-score: ', 0.6282254180141746, 'precision: ', 1.0, 'recall: ', 0.45796548956661315)\n",
      "('epoch end ', 0.15, ', f1-score: ', 0.6125687243371146, 'precision: ', 1.0, 'recall: ', 0.4415128410914928)\n",
      "('epoch end ', 0.2, ', f1-score: ', 0.5987207422506502, 'precision: ', 1.0, 'recall: ', 0.4272672552166934)\n",
      "('epoch end ', 0.25, ', f1-score: ', 0.5888015856161959, 'precision: ', 1.0, 'recall: ', 0.4172351524879615)\n",
      "('epoch end ', 0.3, ', f1-score: ', 0.5787409995009625, 'precision: ', 1.0, 'recall: ', 0.40720304975922955)\n",
      "('epoch end ', 0.35000000000000003, ', f1-score: ', 0.5689469528389922, 'precision: ', 1.0, 'recall: ', 0.39757223113964685)\n",
      "('epoch end ', 0.4, ', f1-score: ', 0.5607854461449611, 'precision: ', 1.0, 'recall: ', 0.38964686998394865)\n",
      "('epoch end ', 0.45, ', f1-score: ', 0.5501090909090909, 'precision: ', 1.0, 'recall: ', 0.37941412520064205)\n",
      "('epoch end ', 0.5, ', f1-score: ', 0.5405563689604685, 'precision: ', 1.0, 'recall: ', 0.3703852327447833)\n",
      "('epoch end ', 0.55, ', f1-score: ', 0.5318506517416599, 'precision: ', 1.0, 'recall: ', 0.36225922953451045)\n",
      "('epoch end ', 0.6, ', f1-score: ', 0.5221645663454411, 'precision: ', 1.0, 'recall: ', 0.353330658105939)\n",
      "('epoch end ', 0.65, ', f1-score: ', 0.5116834639790967, 'precision: ', 1.0, 'recall: ', 0.34380016051364365)\n",
      "('epoch end ', 0.7000000000000001, ', f1-score: ', 0.49981187448265485, 'precision: ', 1.0, 'recall: ', 0.3331661316211878)\n",
      "('epoch end ', 0.75, ', f1-score: ', 0.4878640776699029, 'precision: ', 1.0, 'recall: ', 0.32263242375601925)\n",
      "('epoch end ', 0.8, ', f1-score: ', 0.4744413835322926, 'precision: ', 1.0, 'recall: ', 0.3109951845906902)\n",
      "('epoch end ', 0.85, ', f1-score: ', 0.4552921121958779, 'precision: ', 1.0, 'recall: ', 0.29474317817014445)\n",
      "Epoch 20/100\n",
      "89684/89684 [==============================] - 56s 626us/step - loss: 0.0464 - acc: 0.9847 - val_loss: 1.2924 - val_acc: 0.7388\n",
      "('epoch end ', 0.1, ', f1-score: ', 0.6284141726866185, 'precision: ', 1.0, 'recall: ', 0.4581661316211878)\n",
      "('epoch end ', 0.15, ', f1-score: ', 0.6123755829331106, 'precision: ', 1.0, 'recall: ', 0.44131219903691815)\n",
      "('epoch end ', 0.2, ', f1-score: ', 0.599409863706618, 'precision: ', 1.0, 'recall: ', 0.42796950240770465)\n",
      "('epoch end ', 0.25, ', f1-score: ', 0.5883019402350943, 'precision: ', 1.0, 'recall: ', 0.4167335473515249)\n",
      "('epoch end ', 0.3, ', f1-score: ', 0.57843696520251, 'precision: ', 1.0, 'recall: ', 0.4069020866773676)\n",
      "('epoch end ', 0.35000000000000003, ', f1-score: ', 0.5691523720663173, 'precision: ', 1.0, 'recall: ', 0.3977728731942215)\n",
      "('epoch end ', 0.4, ', f1-score: ', 0.5604736804101379, 'precision: ', 1.0, 'recall: ', 0.3893459069020867)\n",
      "('epoch end ', 0.45, ', f1-score: ', 0.5508468416079088, 'precision: ', 1.0, 'recall: ', 0.3801163723916533)\n",
      "('epoch end ', 0.5, ', f1-score: ', 0.5407700190308886, 'precision: ', 1.0, 'recall: ', 0.37058587479935795)\n",
      "('epoch end ', 0.55, ', f1-score: ', 0.5322830008098358, 'precision: ', 1.0, 'recall: ', 0.3626605136436597)\n",
      "('epoch end ', 0.6, ', f1-score: ', 0.521616611049314, 'precision: ', 1.0, 'recall: ', 0.3528290529695024)\n",
      "('epoch end ', 0.65, ', f1-score: ', 0.5122388059701493, 'precision: ', 1.0, 'recall: ', 0.34430176565008025)\n",
      "('epoch end ', 0.7000000000000001, ', f1-score: ', 0.5001504664459825, 'precision: ', 1.0, 'recall: ', 0.33346709470304975)\n",
      "('epoch end ', 0.75, ', f1-score: ', 0.4884373341420881, 'precision: ', 1.0, 'recall: ', 0.32313402889245585)\n",
      "('epoch end ', 0.8, ', f1-score: ', 0.4751415022181429, 'precision: ', 1.0, 'recall: ', 0.31159711075441415)\n",
      "('epoch end ', 0.85, ', f1-score: ', 0.4556510961344798, 'precision: ', 1.0, 'recall: ', 0.2950441412520064)\n",
      "Epoch 21/100\n",
      "89684/89684 [==============================] - 56s 627us/step - loss: 0.0464 - acc: 0.9847 - val_loss: 1.2934 - val_acc: 0.7395\n",
      "('epoch end ', 0.1, ', f1-score: ', 0.6251034482758621, 'precision: ', 1.0, 'recall: ', 0.4546548956661316)\n",
      "('epoch end ', 0.15, ', f1-score: ', 0.6087927424982554, 'precision: ', 1.0, 'recall: ', 0.4376003210272873)\n",
      "('epoch end ', 0.2, ', f1-score: ', 0.5955618175413878, 'precision: ', 1.0, 'recall: ', 0.4240569823434992)\n",
      "('epoch end ', 0.25, ', f1-score: ', 0.5847944913750266, 'precision: ', 1.0, 'recall: ', 0.4132223113964687)\n",
      "('epoch end ', 0.3, ', f1-score: ', 0.5755930265790227, 'precision: ', 1.0, 'recall: ', 0.40409309791332265)\n",
      "('epoch end ', 0.35000000000000003, ', f1-score: ', 0.5653425446171559, 'precision: ', 1.0, 'recall: ', 0.3940609951845907)\n",
      "('epoch end ', 0.4, ', f1-score: ', 0.5566174341152621, 'precision: ', 1.0, 'recall: ', 0.38563402889245585)\n",
      "('epoch end ', 0.45, ', f1-score: ', 0.5463030479801663, 'precision: ', 1.0, 'recall: ', 0.37580256821829855)\n",
      "('epoch end ', 0.5, ', f1-score: ', 0.537451397549703, 'precision: ', 1.0, 'recall: ', 0.36747592295345105)\n",
      "('epoch end ', 0.55, ', f1-score: ', 0.5279480174259765, 'precision: ', 1.0, 'recall: ', 0.35864767255216695)\n",
      "('epoch end ', 0.6, ', f1-score: ', 0.5175490779298036, 'precision: ', 1.0, 'recall: ', 0.3491171749598716)\n",
      "('epoch end ', 0.65, ', f1-score: ', 0.5080077832659782, 'precision: ', 1.0, 'recall: ', 0.3404895666131621)\n",
      "('epoch end ', 0.7000000000000001, ', f1-score: ', 0.49596378725009427, 'precision: ', 1.0, 'recall: ', 0.32975521669341895)\n",
      "('epoch end ', 0.75, ', f1-score: ', 0.4851063829787234, 'precision: ', 1.0, 'recall: ', 0.3202247191011236)\n",
      "('epoch end ', 0.8, ', f1-score: ', 0.47128287707997857, 'precision: ', 1.0, 'recall: ', 0.3082865168539326)\n",
      "('epoch end ', 0.85, ', f1-score: ', 0.45229407654685194, 'precision: ', 1.0, 'recall: ', 0.2922351524879615)\n",
      "Epoch 22/100\n",
      "89684/89684 [==============================] - 56s 629us/step - loss: 0.0468 - acc: 0.9842 - val_loss: 1.2919 - val_acc: 0.7391\n",
      "('epoch end ', 0.1, ', f1-score: ', 0.6313332417959632, 'precision: ', 1.0, 'recall: ', 0.4612760834670947)\n",
      "('epoch end ', 0.15, ', f1-score: ', 0.6156516908548018, 'precision: ', 1.0, 'recall: ', 0.444723113964687)\n",
      "('epoch end ', 0.2, ', f1-score: ', 0.601767428811895, 'precision: ', 1.0, 'recall: ', 0.4303772070626003)\n",
      "('epoch end ', 0.25, ', f1-score: ', 0.5902984019233489, 'precision: ', 1.0, 'recall: ', 0.41873996789727125)\n",
      "('epoch end ', 0.3, ', f1-score: ', 0.581067615658363, 'precision: ', 1.0, 'recall: ', 0.4095104333868379)\n",
      "('epoch end ', 0.35000000000000003, ', f1-score: ', 0.5726354979594759, 'precision: ', 1.0, 'recall: ', 0.40118378812199035)\n",
      "('epoch end ', 0.4, ', f1-score: ', 0.5628604382929642, 'precision: ', 1.0, 'recall: ', 0.391653290529695)\n",
      "('epoch end ', 0.45, ', f1-score: ', 0.5545243619489559, 'precision: ', 1.0, 'recall: ', 0.38362760834670945)\n",
      "('epoch end ', 0.5, ', f1-score: ', 0.544073614255459, 'precision: ', 1.0, 'recall: ', 0.37369582664526485)\n",
      "('epoch end ', 0.55, ', f1-score: ', 0.5353023289986041, 'precision: ', 1.0, 'recall: ', 0.36546950240770465)\n",
      "('epoch end ', 0.6, ', f1-score: ', 0.5259889094269871, 'precision: ', 1.0, 'recall: ', 0.3568418940609952)\n",
      "('epoch end ', 0.65, ', f1-score: ', 0.5154516345223025, 'precision: ', 1.0, 'recall: ', 0.3472110754414125)\n",
      "('epoch end ', 0.7000000000000001, ', f1-score: ', 0.5046504650465047, 'precision: ', 1.0, 'recall: ', 0.33747993579454255)\n",
      "('epoch end ', 0.75, ', f1-score: ', 0.4922099531084556, 'precision: ', 1.0, 'recall: ', 0.3264446227929374)\n",
      "('epoch end ', 0.8, ', f1-score: ', 0.47712168665495375, 'precision: ', 1.0, 'recall: ', 0.31330256821829855)\n",
      "('epoch end ', 0.85, ', f1-score: ', 0.45970795024337485, 'precision: ', 1.0, 'recall: ', 0.2984550561797753)\n",
      "Epoch 23/100\n",
      "89684/89684 [==============================] - 56s 629us/step - loss: 0.0460 - acc: 0.9849 - val_loss: 1.2959 - val_acc: 0.7389\n",
      "('epoch end ', 0.1, ', f1-score: ', 0.6246291824767161, 'precision: ', 1.0, 'recall: ', 0.454153290529695)\n",
      "('epoch end ', 0.15, ', f1-score: ', 0.6083071553228621, 'precision: ', 1.0, 'recall: ', 0.4370987158908507)\n",
      "('epoch end ', 0.2, ', f1-score: ', 0.5956607495069034, 'precision: ', 1.0, 'recall: ', 0.4241573033707865)\n",
      "('epoch end ', 0.25, ', f1-score: ', 0.5845935392261271, 'precision: ', 1.0, 'recall: ', 0.41302166934189405)\n",
      "('epoch end ', 0.3, ', f1-score: ', 0.5746764853077858, 'precision: ', 1.0, 'recall: ', 0.40319020866773675)\n",
      "('epoch end ', 0.35000000000000003, ', f1-score: ', 0.5654457796646758, 'precision: ', 1.0, 'recall: ', 0.394161316211878)\n",
      "('epoch end ', 0.4, ', f1-score: ', 0.5553623188405797, 'precision: ', 1.0, 'recall: ', 0.38443017656500805)\n",
      "('epoch end ', 0.45, ', f1-score: ', 0.5458789204959884, 'precision: ', 1.0, 'recall: ', 0.3754012841091493)\n",
      "('epoch end ', 0.5, ', f1-score: ', 0.5365925273434633, 'precision: ', 1.0, 'recall: ', 0.3666733547351525)\n",
      "('epoch end ', 0.55, ', f1-score: ', 0.5283826677493172, 'precision: ', 1.0, 'recall: ', 0.3590489566613162)\n",
      "('epoch end ', 0.6, ', f1-score: ', 0.5172182967645965, 'precision: ', 1.0, 'recall: ', 0.34881621187800965)\n",
      "('epoch end ', 0.65, ', f1-score: ', 0.5077844311377245, 'precision: ', 1.0, 'recall: ', 0.3402889245585875)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('epoch end ', 0.7000000000000001, ', f1-score: ', 0.49562330214307276, 'precision: ', 1.0, 'recall: ', 0.329454253611557)\n",
      "('epoch end ', 0.75, ', f1-score: ', 0.4844153869545386, 'precision: ', 1.0, 'recall: ', 0.3196227929373997)\n",
      "('epoch end ', 0.8, ', f1-score: ', 0.47116564417177914, 'precision: ', 1.0, 'recall: ', 0.30818619582664525)\n",
      "('epoch end ', 0.85, ', f1-score: ', 0.45133224578575315, 'precision: ', 1.0, 'recall: ', 0.2914325842696629)\n",
      "Epoch 00023: early stopping\n"
     ]
    }
   ],
   "source": [
    "class Metrics(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.val_f1s = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        #import pdb; pdb.set_trace()\n",
    "        val_predict = (np.asarray(self.model.predict(self.validation_data[:4])))#\n",
    "        val_label = self.validation_data[-2]\n",
    "        for weight in range(10, 90, 5):\n",
    "            val_pred = [1 if item > weight*0.01 else 0 for item in val_predict]\n",
    "            _val_f1 = f1_score(val_label, val_pred)\n",
    "            print(\"epoch end \", weight*0.01, \", f1-score: \", _val_f1, \"precision: \", \n",
    "                  precision_score(val_label, val_pred, average='binary'), \"recall: \", \n",
    "                  recall_score(val_label, val_pred, average='binary'))\n",
    "metrics = Metrics()\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint,ReduceLROnPlateau\n",
    "X_train_q1 = word_squence_ques1_char\n",
    "X_train_q2 = word_squence_ques2_char\n",
    "X_train_q1_com = np.array(comman_sen1)\n",
    "X_train_q2_com = np.array(comman_sen2)\n",
    "y_train = train_data_char_df.iloc[:, 3]\n",
    "\n",
    "class_weight = {0: 1.,\n",
    "                1: 3.,}\n",
    "\n",
    "X_fold_val_q1_out,X_fold_val_q2_out, X_fold_val_magic_out = [0, 0, 0]\n",
    "\n",
    "def model_train(model_func, X_train_q1, X_train_q2, y_train, model_checkpoint_path):\n",
    "    NUM_FOLDS = 10\n",
    "    kfold = StratifiedKFold(\n",
    "        n_splits=NUM_FOLDS,\n",
    "        shuffle=True,\n",
    "        random_state=30\n",
    "    )\n",
    "    BATCH_SIZE = 128\n",
    "    MAX_EPOCHS = 100\n",
    "\n",
    "    for fold_num, (ix_train, ix_val) in enumerate(kfold.split(X_train_q1, y_train)):\n",
    "\n",
    "        # Augment the training set by mirroring the pairs.\n",
    "        #ix_train = ix_val = int(X_train_q1.shape[0]*0.8)\n",
    "        X_fold_train_q1 = np.vstack([X_train_q1[ix_train], X_train_q2[ix_train]])\n",
    "        X_fold_train_q2 = np.vstack([X_train_q2[ix_train], X_train_q1[ix_train]])\n",
    "        X_fold_train_q1_com = np.vstack([X_train_q1_com[ix_train], X_train_q2_com[ix_train]])\n",
    "        X_fold_train_q2_com = np.vstack([X_train_q2_com[ix_train], X_train_q1_com[ix_train]])\n",
    "#         X_fold_train_q10 = np.vstack([X_train_q10[ix_train], X_train_q20[ix_train]])\n",
    "#         X_fold_train_q20 = np.vstack([X_train_q20[ix_train], X_train_q10[ix_train]])\n",
    "        #X_fold_train_magic = np.vstack([X_train_magic[ix_train], X_train_magic[ix_train]])\n",
    "\n",
    "        X_fold_val_q1 = np.vstack([X_train_q1[ix_val], X_train_q2[ix_val]])\n",
    "        X_fold_val_q2 = np.vstack([X_train_q2[ix_val], X_train_q1[ix_val]])\n",
    "        X_fold_val_q1_com = np.vstack([X_train_q1_com[ix_val], X_train_q2_com[ix_val]])\n",
    "        X_fold_val_q2_com = np.vstack([X_train_q2_com[ix_val], X_train_q1_com[ix_val]])\n",
    "#         X_fold_val_q10 = np.vstack([X_train_q10[ix_val], X_train_q20[ix_val]])\n",
    "#         X_fold_val_q20 = np.vstack([X_train_q20[ix_val], X_train_q10[ix_val]])\n",
    "        #X_fold_val_magic = np.vstack([X_train_magic[ix_val], X_train_magic[ix_val]])\n",
    "        \n",
    "        \n",
    "        # Ground truth should also be \"mirrored\".\n",
    "        y_fold_train = np.concatenate([y_train[ix_train], y_train[ix_train]])\n",
    "        y_fold_val = np.concatenate([y_train[ix_val], y_train[ix_val]])\n",
    "\n",
    "        print('Fitting fold')\n",
    "\n",
    "        # Compile a new model.\n",
    "        # model1 = create_model_cnn(model_params)\n",
    "        model = model_func(model_params)\n",
    "\n",
    "        model.compile(optimizer= keras.optimizers.Adam(lr = 0.0005), loss=\"binary_crossentropy\", \n",
    "            metrics=['accuracy'])\n",
    "        # Train.\n",
    "        model.fit(\n",
    "            [X_fold_train_q1, X_fold_train_q2, \n",
    "             X_fold_train_q1_com, X_fold_train_q2_com,\n",
    "            # X_fold_train_q10, X_fold_train_q20, \n",
    "#              X_fold_train_char0_len, X_fold_train_char1_len,\n",
    "#              X_fold_train_word0_len, X_fold_train_word1_len,\n",
    "             # X_fold_train_magic\n",
    "            ], y_fold_train,#\n",
    "            validation_data=([\n",
    "                X_fold_val_q1, X_fold_val_q2, \n",
    "             X_fold_val_q1_com, X_fold_val_q2_com,\n",
    "                           #   X_fold_val_q10, X_fold_val_q20, \n",
    "#                               X_fold_val_char0_len, X_fold_val_char1_len,\n",
    "#                               X_fold_val_word0_len,X_fold_val_word1_len,\n",
    "                              # X_fold_val_magic\n",
    "                             ], y_fold_val),#\n",
    "\n",
    "            batch_size=BATCH_SIZE,\n",
    "            epochs=MAX_EPOCHS,\n",
    "            verbose=1,\n",
    "            shuffle=True,\n",
    "            # class_weight=class_weight,\n",
    "\n",
    "            callbacks=[\n",
    "                # Stop training when the validation loss stops improving.\n",
    "                EarlyStopping(\n",
    "                    monitor='val_loss',\n",
    "                    min_delta=0.001,\n",
    "                    patience=20,\n",
    "                    verbose=1,\n",
    "                    mode='auto',\n",
    "                ),\n",
    "                ReduceLROnPlateau(\n",
    "                    monitor='val_loss', \n",
    "                    factor=0.1, \n",
    "                    patience=5, \n",
    "                    min_delta=0.0001,\n",
    "                    cooldown=1, \n",
    "                ),\n",
    "                # Save the weights of the best epoch.\n",
    "#                 ModelCheckpoint(\n",
    "#                     os.path.join(model_checkpoint_path + str(fold_num) + 'weights.{epoch:02d}.hdf5'),\n",
    "#                     monitor='val_loss',\n",
    "#                     save_best_only=False,\n",
    "#                     verbose=2,\n",
    "#                     mode='auto',\n",
    "#                 ),\n",
    "                metrics\n",
    "            ],\n",
    "        )\n",
    "        break\n",
    "\n",
    "model_path = '../data/checkpoints/test/'\n",
    "\n",
    "\n",
    "model_params = {\n",
    "    'dense_dropout_rate': 0.3,\n",
    "    'num_dense': 150,\n",
    "    'num_lstm': 128,\n",
    "    'num_filters':32\n",
    "}\n",
    "\n",
    "model_train(build_model_combine, X_train_q1, X_train_q2, y_train, model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    27405\n",
       "1     7595\n",
       "Name: 3, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_char_df.iloc[:, 3].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
